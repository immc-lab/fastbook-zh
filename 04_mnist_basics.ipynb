{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dnwBaJ6nsoPp"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3xLMnaxFsoPv"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "CU9C7buFsoPw"
   },
   "source": [
    "[[chapter_mnist_basics]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxHKkN04soPx",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Under the Hood: Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jztZ2QpJuFp8"
   },
   "source": [
    "# 在内部:训练数字分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40ZwYZlmsoP1"
   },
   "source": [
    "Having seen what it looks like to actually train a variety of models in Chapter 2, let’s now look under the hood and see exactly what is going on. We’ll start by using computer vision to introduce fundamental tools and concepts for deep learning.\n",
    "\n",
    "To be exact, we'll discuss the roles of arrays and tensors and of broadcasting, a powerful technique for using them expressively. We'll explain stochastic gradient descent (SGD), the mechanism for learning by updating weights automatically. We'll discuss the choice of a loss function for our basic classification task, and the role of mini-batches. We'll also describe the math that a basic neural network is actually doing. Finally, we'll put all these pieces together.\n",
    "\n",
    "In future chapters we’ll do deep dives into other applications as well, and see how these concepts and tools generalize. But this chapter is about laying foundation stones. To be frank, that also makes this one of the hardest chapters, because of how these concepts all depend on each other. Like an arch, all the stones need to be in place for the structure to stay up. Also like an arch, once that happens, it's a powerful structure that can support other things. But it requires some patience to assemble.\n",
    "\n",
    "Let's begin. The first step is to consider how images are represented in a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG5fyndrvxdV"
   },
   "source": [
    "在第2章中，我们已经了解了训练各种模型是什么样子的，现在让我们看看它的内部结构，看看到底发生了什么。我们将首先使用计算机视觉介绍深度学习的基本工具和概念。\n",
    "\n",
    "确切地说，我们将讨论数组和张量以及广播的作用，广播是一种表达它们的强大技术。我们将解释随机梯度下降(SGD)，这是一种通过自动更新权重进行学习的机制。我们将讨论基本分类任务的损失函数的选择，以及小批量的作用。我们还将描述基本神经网络实际执行的数学运算。最后，我们将把所有这些碎片放在一起。\n",
    "\n",
    "在之后的章节中，我们也将深入研究其他应用程序，并了解这些概念和工具是如何推广的。但这一章是关于奠定基石的。坦白地说，这也使这一章成为最难的章节之一，因为这些概念都是相互依赖的。就像拱门一样，所有的石头都要到位，才能支撑起整个结构。也像拱门一样，它是一个强大的结构，可以支撑其他东西。但组装需要一定的耐心。\n",
    "\n",
    "让我们开始吧。第一步是考虑图像在计算机中是如何表示的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBGPOEFasoP3"
   },
   "source": [
    "## Pixels: The Foundations of Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veazF5TQv5RE"
   },
   "source": [
    "## 像素:计算机视觉的基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCngZsttsoP4"
   },
   "source": [
    "In order to understand what happens in a computer vision model, we first have to understand how computers handle images. We'll use one of the most famous datasets in computer vision, [MNIST](https://en.wikipedia.org/wiki/MNIST_database), for our experiments. MNIST contains images of handwritten digits, collected by the National Institute of Standards and Technology and collated into a machine learning dataset by Yann Lecun and his colleagues. Lecun used MNIST in 1998 in [Lenet-5](http://yann.lecun.com/exdb/lenet/), the first computer system to demonstrate practically useful recognition of handwritten digit sequences. This was one of the most important breakthroughs in the history of AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5j8iGe9v-gn"
   },
   "source": [
    "为了了解计算机视觉模型中发生了什么，我们首先要了解计算机如何处理图像。我们将使用计算机视觉中最著名的数据集之一[MNIST](https://en.wikipedia.org/wiki/MNIST_database)进行实验。MNIST包含手写数字的图像，由美国国家标准与技术研究所收集，并由Yann Lecun和他的同事整理成机器学习数据集。1998年，Lecun在[Lenet-5](http://yann.lecun.com/exdb/lenet/)中使用了MNIST，这是第一个演示了对手写数字序列进行了实用识别的计算机系统。这是人工智能历史上最重要的突破之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urv2PqoxsoP5"
   },
   "source": [
    "## Sidebar: Tenacity and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahy0ZiV8wMaf"
   },
   "source": [
    "## 侧边栏:坚韧和深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpEJ9uGxsoP6"
   },
   "source": [
    "The story of deep learning is one of tenacity and grit by a handful of dedicated researchers. After early hopes (and hype!) neural networks went out of favor in the 1990's and 2000's, and just a handful of researchers kept trying to make them work well. Three of them, Yann Lecun, Yoshua Bengio, and Geoffrey Hinton, were awarded the highest honor in computer science, the Turing Award (generally considered the \"Nobel Prize of computer science\"), in 2018 after triumphing despite the deep skepticism and disinterest of the wider machine learning and statistics community.\n",
    "\n",
    "Geoff Hinton has told of how even academic papers showing dramatically better results than anything previously published would be rejected by top journals and conferences, just because they used a neural network. Yann Lecun's work on convolutional neural networks, which we will study in the next section, showed that these models could read handwritten text—something that had never been achieved before. However, his breakthrough was ignored by most researchers, even as it was used commercially to read 10% of the checks in the US!\n",
    "\n",
    "In addition to these three Turing Award winners, there are many other researchers who have battled to get us to where we are today. For instance, Jurgen Schmidhuber (who many believe should have shared in the Turing Award) pioneered many important ideas, including working with his student Sepp Hochreiter on the long short-term memory (LSTM) architecture (widely used for speech recognition and other text modeling tasks, and used in the IMDb example in <<chapter_intro>>). Perhaps most important of all, Paul Werbos in 1974 invented back-propagation for neural networks, the technique shown in this chapter and used universally for training neural networks ([Werbos 1994](https://books.google.com/books/about/The_Roots_of_Backpropagation.html?id=WdR3OOM2gBwC)). His development was almost entirely ignored for decades, but today it is considered the most important foundation of modern AI.\n",
    "\n",
    "There is a lesson here for all of us! On your deep learning journey you will face many obstacles, both technical, and (even more difficult) posed by people around you who don't believe you'll be successful. There's one *guaranteed* way to fail, and that's to stop trying. We've seen that the only consistent trait amongst every fast.ai student that's gone on to be a world-class practitioner is that they are all very tenacious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNE3aEhYwSjc"
   },
   "source": [
    "深度学习的故事是少数敬业的研究人员坚韧不拔的故事之一。在早期的希望(和炒作!)之后，神经网络在20世纪90年代和2000年代都不受欢迎，只有少数研究人员一直试图让它们运作良好。2018年，他们中的三位Yann Lecun、Yoshua Bengio和Geoffrey Hinton被授予了计算机科学的最高荣誉——图灵奖(通常被认为是“计算机科学的诺贝尔奖”)，尽管更广泛的机器学习和统计界对此深表怀疑和不感兴趣。\n",
    "\n",
    "Geoff Hinton曾说过，即使是那些表现出比以前发表的任何文章都好得多的学术论文，也会因为使用了神经网络而被顶级期刊和会议拒绝。Yann Lecun在卷积神经网络方面的工作(我们将在下一节中研究)表明，这些模型可以读取手写文本——这是以前从未实现过的。然而，他的突破被大多数研究人员忽略了，即使它在商业上被用来读取美国10%的支票！\n",
    "\n",
    "除了这三位图灵奖得主，还有许多其他的研究人员为我们取得今天的成就而奋斗。例如，Jurgen Schmidhuber(许多人认为他应该分享图灵奖)开创了许多重要的想法，包括与他的学生Sepp Hochreiter一起研究长短期记忆(LSTM)架构(广泛用于语音识别和其他文本建模任务，并在<<chapter_intro>>的IMDb示例中使用)。也许最重要的是，Paul Werbos在1974年发明了神经网络的反向传播，该技术在本章中展示并普遍用于训练神经网络([Werbos 1994](https://books.google.com/books/about/The_Roots_of_Backpropagation.html?id=WdR3OOM2gBwC))。几十年来，他的发展几乎被完全忽视，但今天它被认为是现代人工智能最重要的基础。\n",
    "\n",
    "这里给我们所有人上了一课！在你的深度学习之旅中，你将面临许多障碍，既有技术上的障碍，也有(甚至更困难的)周围不相信你会成功的人造成的障碍。有一种方式*注定*会失败，那就是停止尝试。我们已经看到，每个成为世界级从业者的 fast.ai 学生唯一一致的特征是他们都非常顽强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY9NlYcesoP8"
   },
   "source": [
    "## End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUzYLxz5wctu"
   },
   "source": [
    "## 结束侧边栏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqvjgXTEsoP9"
   },
   "source": [
    "For this initial tutorial we are just going to try to create a model that can classify any image as a 3 or a 7. So let's download a sample of MNIST that contains images of just these digits:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPYgFATSwkHt"
   },
   "source": [
    "对于这个初始教程，我们将尝试创建一个可以将任何图像分类为 3 或 7 的模型。因此，让我们下载一个仅包含这些数字图像的 MNIST 样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iK3A8FO_soP9"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OH20dT1FsoP-"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyaDxKNcsoP-"
   },
   "source": [
    "We can see what's in this directory by using `ls`, a method added by fastai. This method returns an object of a special fastai class called `L`, which has all the same functionality of Python's built-in `list`, plus a lot more. One of its handy features is that, when printed, it displays the count of items, before listing the items themselves (if there are more than 10 items, it just shows the first few):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zpNEY25wpBy"
   },
   "source": [
    "通过使用`ls` (fastai添加的方法)，我们可以看到这个目录中有什么。此方法返回一个名为`L`的特殊fastai类的对象，该对象具有Python内置`list`的所有相同功能，以及更多功能。它的一个方便的功能是，当打印时，它会在列出项目本身之前显示项目的数量(如果有超过10个项目，它只显示前几个):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NXmGV9JhsoP_",
    "outputId": "e71d89d9-96c6-438e-dde8-fdcb14e41576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('train'),Path('valid')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-d-BEV7soQA"
   },
   "source": [
    "The MNIST dataset follows a common layout for machine learning datasets: separate folders for the training set and the validation set (and/or test set). Let's see what's inside the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcs6xy_RxLtW"
   },
   "source": [
    "MNIST数据集遵循机器学习数据集的常见布局:训练集和验证集(和/或测试集)的单独文件夹。让我们看看训练集中有什么:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C5uEdFTEsoQB",
    "outputId": "fa6368aa-d2af-4066-b977-acaea1d868d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCvm7WXbsoQC"
   },
   "source": [
    "There's a folder of 3s, and a folder of 7s. In machine learning parlance, we say that \"3\" and \"7\" are the *labels* (or targets) in this dataset. Let's take a look in one of these folders (using `sorted` to ensure we all get the same order of files):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd-eHkwCxQEk"
   },
   "source": [
    "一个是3s文件夹，一个是7s文件夹。用机器学习的术语来说，我们说“3”和“7”是这个数据集中的*标签*(或目标)。让我们看看其中一个文件夹(使用`sorted`以确保我们得到相同的文件顺序):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Eewt9JWgsoQC",
    "outputId": "71fd17f6-f240-41b7-f8f0-9a8765eead4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ktKzDusoQD"
   },
   "source": [
    "As we might expect, it's full of image files. Let’s take a look at one now. Here’s an image of a handwritten number 3, taken from the famous MNIST dataset of handwritten numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4m9HCVLxT4g"
   },
   "source": [
    "正如我们所料，它充满了图像文件。现在我们来看一个。这是一张手写数字3的图片，取自著名的MNIST手写数字数据集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yHcG_EXQsoQD",
    "outputId": "6a57d779-243d-43a0-f277-a5ed530c2b41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3AsWDQqsoQE"
   },
   "source": [
    "Here we are using the `Image` class from the *Python Imaging Library* (PIL), which is the most widely used Python package for opening, manipulating, and viewing images. Jupyter knows about PIL images, so it displays the image for us automatically.\n",
    "\n",
    "In a computer, everything is represented as a number. To view the numbers that make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*. For instance, here's what a section of the image looks like, converted to a NumPy array:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmQB-h6ExXhJ"
   },
   "source": [
    "这里我们使用*Python图像库* (PIL)的`Image`类，它是用于打开、操作和查看图像的最广泛使用的Python包。Jupyter知道PIL图像，所以它会自动为我们显示图像。\n",
    "\n",
    "在计算机中，一切都表示为数字。为了查看组成这个图像的数字，我们必须将其转换为*NumPy数组*或*PyTorch张量*。例如，下面是转换成NumPy数组的图像部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4C0xeGMIsoQE",
    "outputId": "d27a3ad4-1c6f-427c-9bc6-09f332dca860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX6H58twsoQF"
   },
   "source": [
    "The `4:10` indicates we requested the rows from index 4 (included) to 10 (not included) and the same for the columns. NumPy indexes from top to bottom and left to right, so this section is located in the top-left corner of the image. Here's the same thing as a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i8-wsKcxcGH"
   },
   "source": [
    "`4:10`表示我们请求索引4(包括)到10(不包括)的行，列也是如此。NumPy从上到下、从左到右进行索引，因此这个部分位于图像的左上角。这里与PyTorch张量相同:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7hGFPMcjsoQG",
    "outputId": "1e0273d8-6d67-49f6-ce32-9a2aedf499fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAj_aXVssoQG"
   },
   "source": [
    "We can slice the array to pick just the part with the top of the digit in it, and then use a Pandas DataFrame to color-code the values using a gradient, which shows us clearly how the image is created from the pixel values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpyHk7ZOxfrk"
   },
   "source": [
    "我们可以对数组进行切片，只挑选数字顶部的部分，然后使用Pandas DataFrame使用梯度对值进行颜色编码，这清楚地向我们展示了如何从像素值创建图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4r436E2SsoQH",
    "outputId": "899fe772-3ad2-4f78-d0d1-d2aa911f2213"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c644a_row0_col0, #T_c644a_row0_col1, #T_c644a_row0_col2, #T_c644a_row0_col3, #T_c644a_row0_col4, #T_c644a_row0_col5, #T_c644a_row0_col6, #T_c644a_row0_col7, #T_c644a_row0_col8, #T_c644a_row0_col9, #T_c644a_row0_col10, #T_c644a_row0_col11, #T_c644a_row0_col12, #T_c644a_row0_col13, #T_c644a_row0_col14, #T_c644a_row0_col15, #T_c644a_row0_col16, #T_c644a_row0_col17, #T_c644a_row1_col0, #T_c644a_row1_col1, #T_c644a_row1_col2, #T_c644a_row1_col3, #T_c644a_row1_col4, #T_c644a_row1_col15, #T_c644a_row1_col16, #T_c644a_row1_col17, #T_c644a_row2_col0, #T_c644a_row2_col1, #T_c644a_row2_col2, #T_c644a_row2_col15, #T_c644a_row2_col16, #T_c644a_row2_col17, #T_c644a_row3_col0, #T_c644a_row3_col15, #T_c644a_row3_col16, #T_c644a_row3_col17, #T_c644a_row4_col0, #T_c644a_row4_col6, #T_c644a_row4_col7, #T_c644a_row4_col8, #T_c644a_row4_col9, #T_c644a_row4_col10, #T_c644a_row4_col15, #T_c644a_row4_col16, #T_c644a_row4_col17, #T_c644a_row5_col0, #T_c644a_row5_col5, #T_c644a_row5_col6, #T_c644a_row5_col7, #T_c644a_row5_col8, #T_c644a_row5_col9, #T_c644a_row5_col15, #T_c644a_row5_col16, #T_c644a_row5_col17, #T_c644a_row6_col0, #T_c644a_row6_col1, #T_c644a_row6_col2, #T_c644a_row6_col3, #T_c644a_row6_col4, #T_c644a_row6_col5, #T_c644a_row6_col6, #T_c644a_row6_col7, #T_c644a_row6_col8, #T_c644a_row6_col9, #T_c644a_row6_col14, #T_c644a_row6_col15, #T_c644a_row6_col16, #T_c644a_row6_col17, #T_c644a_row7_col0, #T_c644a_row7_col1, #T_c644a_row7_col2, #T_c644a_row7_col3, #T_c644a_row7_col4, #T_c644a_row7_col5, #T_c644a_row7_col6, #T_c644a_row7_col13, #T_c644a_row7_col14, #T_c644a_row7_col15, #T_c644a_row7_col16, #T_c644a_row7_col17, #T_c644a_row8_col0, #T_c644a_row8_col1, #T_c644a_row8_col2, #T_c644a_row8_col3, #T_c644a_row8_col4, #T_c644a_row8_col13, #T_c644a_row8_col14, #T_c644a_row8_col15, #T_c644a_row8_col16, #T_c644a_row8_col17, #T_c644a_row9_col0, #T_c644a_row9_col1, #T_c644a_row9_col2, #T_c644a_row9_col3, #T_c644a_row9_col4, #T_c644a_row9_col16, #T_c644a_row9_col17, #T_c644a_row10_col0, #T_c644a_row10_col1, #T_c644a_row10_col2, #T_c644a_row10_col3, #T_c644a_row10_col4, #T_c644a_row10_col5, #T_c644a_row10_col6, #T_c644a_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row1_col6, #T_c644a_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row1_col8, #T_c644a_row1_col9, #T_c644a_row1_col10, #T_c644a_row2_col5, #T_c644a_row2_col6, #T_c644a_row2_col7, #T_c644a_row2_col11, #T_c644a_row2_col12, #T_c644a_row2_col13, #T_c644a_row3_col4, #T_c644a_row3_col12, #T_c644a_row3_col13, #T_c644a_row4_col1, #T_c644a_row4_col2, #T_c644a_row4_col3, #T_c644a_row4_col12, #T_c644a_row4_col13, #T_c644a_row5_col12, #T_c644a_row6_col11, #T_c644a_row9_col11, #T_c644a_row10_col11, #T_c644a_row10_col12, #T_c644a_row10_col13, #T_c644a_row10_col14, #T_c644a_row10_col15, #T_c644a_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row2_col4, #T_c644a_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row2_col8, #T_c644a_row2_col14, #T_c644a_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row2_col9, #T_c644a_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row2_col10, #T_c644a_row7_col10, #T_c644a_row8_col8, #T_c644a_row8_col10, #T_c644a_row9_col8, #T_c644a_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row3_col7, #T_c644a_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row5_col2, #T_c644a_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row5_col4, #T_c644a_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row5_col10, #T_c644a_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row5_col13, #T_c644a_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row6_col10, #T_c644a_row7_col11, #T_c644a_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row8_col9, #T_c644a_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c644a_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row10_col8, #T_c644a_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c644a_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c644a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0</th>\n",
       "      <th class=\"col_heading level0 col1\" >1</th>\n",
       "      <th class=\"col_heading level0 col2\" >2</th>\n",
       "      <th class=\"col_heading level0 col3\" >3</th>\n",
       "      <th class=\"col_heading level0 col4\" >4</th>\n",
       "      <th class=\"col_heading level0 col5\" >5</th>\n",
       "      <th class=\"col_heading level0 col6\" >6</th>\n",
       "      <th class=\"col_heading level0 col7\" >7</th>\n",
       "      <th class=\"col_heading level0 col8\" >8</th>\n",
       "      <th class=\"col_heading level0 col9\" >9</th>\n",
       "      <th class=\"col_heading level0 col10\" >10</th>\n",
       "      <th class=\"col_heading level0 col11\" >11</th>\n",
       "      <th class=\"col_heading level0 col12\" >12</th>\n",
       "      <th class=\"col_heading level0 col13\" >13</th>\n",
       "      <th class=\"col_heading level0 col14\" >14</th>\n",
       "      <th class=\"col_heading level0 col15\" >15</th>\n",
       "      <th class=\"col_heading level0 col16\" >16</th>\n",
       "      <th class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c644a_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c644a_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_c644a_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_c644a_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_c644a_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_c644a_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_c644a_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_c644a_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_c644a_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_c644a_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_c644a_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_c644a_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c644a_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_c644a_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_c644a_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_c644a_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_c644a_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_c644a_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_c644a_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_c644a_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c644a_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_c644a_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_c644a_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_c644a_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_c644a_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_c644a_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_c644a_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_c644a_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_c644a_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_c644a_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_c644a_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_c644a_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_c644a_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_c644a_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_c644a_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c644a_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_c644a_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_c644a_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_c644a_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_c644a_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_c644a_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_c644a_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_c644a_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_c644a_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_c644a_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c644a_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_c644a_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_c644a_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_c644a_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_c644a_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_c644a_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_c644a_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_c644a_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_c644a_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_c644a_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c644a_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_c644a_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_c644a_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_c644a_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_c644a_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c644a_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_c644a_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_c644a_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_c644a_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_c644a_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_c644a_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_c644a_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c644a_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_c644a_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_c644a_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_c644a_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_c644a_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_c644a_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_c644a_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_c644a_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_c644a_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c644a_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_c644a_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_c644a_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_c644a_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_c644a_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_c644a_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_c644a_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_c644a_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_c644a_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_c644a_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_c644a_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_c644a_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_c644a_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c644a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c644a_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_c644a_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_c644a_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_c644a_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_c644a_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_c644a_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_c644a_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_c644a_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_c644a_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_c644a_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_c644a_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_c644a_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19b91102910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeNlz9VYsoQH"
   },
   "source": [
    "<img width=\"453\" id=\"output_pd_pixels\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00058.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgeTp7GFsoQH"
   },
   "source": [
    "You can see that the background white pixels are stored as the number 0, black is the number 255, and shades of gray are between the two. The entire image contains 28 pixels across and 28 pixels down, for a total of 784 pixels. (This is much smaller than an image that you would get from a phone camera, which has millions of pixels, but is a convenient size for our initial learning and experiments. We will build up to bigger, full-color images soon.)\n",
    "\n",
    "So, now you've seen what an image looks like to a computer, let's recall our goal: create a model that can recognize 3s and 7s. How might you go about getting a computer to do that?\n",
    "\n",
    "> Warning: Stop and Think!: Before you read on, take a moment to think about how a computer might be able to recognize these two different digits. What kinds of features might it be able to look at? How might it be able to identify these features? How could it combine them together? Learning works best when you try to solve problems yourself, rather than just reading somebody else's answers; so step away from this book for a few minutes, grab a piece of paper and pen, and jot some ideas down…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2EGuIisxkky"
   },
   "source": [
    "您可以看到，背景白色像素存储为数字0，黑色存储为数字255，灰色阴影位于两者之间。整个图像包含28个像素宽和28个像素高，总共784个像素。(这比你从数百万像素的手机摄像头中得到的图像要小得多，但对于我们最初的学习和实验来说，这是一个方便的尺寸。我们很快就会建立更大的全彩图片。)\n",
    "\n",
    "那么，现在你已经看到了计算机眼中的图像是什么样的，让我们回忆一下我们的目标:创建一个能识别3和7的模型。你怎么能得到一台电脑来做到这一点？\n",
    "\n",
    ">警告:停下来思考一下！在你继续阅读之前，花点时间思考一下计算机是如何识别这两个不同的数字的。它能看到什么样的特征?它如何能够识别这些特征?如何将它们结合在一起?当你试着自己解决问题而不是只是阅读别人的答案时，学习效果最好；所以，离开这本书几分钟，拿起一张纸和一支笔，把一些想法写下……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzKnnteVsoQI"
   },
   "source": [
    "## First Try: Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qaVNMikxqy9"
   },
   "source": [
    "## 第一次尝试:像素相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8j04TQNsoQI"
   },
   "source": [
    "So, here is a first idea: how about we find the average pixel value for every pixel of the 3s, then do the same for the 7s. This will give us two group averages, defining what we might call the \"ideal\" 3 and 7. Then, to classify an image as one digit or the other, we see which of these two ideal digits the image is most similar to. This certainly seems like it should be better than nothing, so it will make a good baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNORdbxfxuz3"
   },
   "source": [
    "所以，这是第一个想法:我们如何找到3s的每个像素的平均像素值，然后对7s做同样的操作。这将为我们提供两组平均值，定义我们可能称之为“理想”的3和7。然后，为了将图像分类为一个数字或另一个数字，我们会看到图像与这两个理想数字中的哪一个最相似。 这样看总比没有均值要好，所以这将是一个很好的基线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tozEYXuvsoQJ"
   },
   "source": [
    "> jargon: Baseline: A simple model which you are confident should perform reasonably well. It should be very simple to implement, and very easy to test, so that you can then test each of your improved ideas, and make sure they are always better than your baseline. Without starting with a sensible baseline, it is very difficult to know whether your super-fancy models are actually any good. One good approach to creating a baseline is doing what we have done here: think of a simple, easy-to-implement model. Another good approach is to search around to find other people that have solved similar problems to yours, and download and run their code on your dataset. Ideally, try both of these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPi1KC-oxyiU"
   },
   "source": [
    ">术语：基线:一个简单的模型，你有信心它应该表现得相当好。它应该很容易实现，很容易测试，这样你就可以测试你的每个改进的想法，并确保它们总是优于你的基线。如果没有一个合理的基线，就很难知道你超级花哨的模型是否真的好。创建基线的一个好方法就是做我们在这里所做的事情:考虑一个简单的、易于实现的模型。另一种好的方法是四处搜索，找到其他与您解决过类似问题的人，然后下载并在您的数据集中运行他们的代码。理想情况下，尝试这两种方法！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO_osIaMsoQJ"
   },
   "source": [
    "Step one for our simple model is to get the average of pixel values for each of our two groups. In the process of doing this, we will learn a lot of neat Python numeric programming tricks!\n",
    "\n",
    "Let's create a tensor containing all of our 3s stacked together. We already know how to create a tensor containing a single image. To create a tensor containing all the images in a directory, we will first use a Python list comprehension to create a plain list of the single image tensors.\n",
    "\n",
    "We will use Jupyter to do some little checks of our work along the way—in this case, making sure that the number of returned items seems reasonable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P42wNtddx4AZ"
   },
   "source": [
    "我们的简单模型的第一步是获得两组像素值的平均值。在这样做的过程中，我们会学到很多简洁的Python数值编程技巧!\n",
    "\n",
    "我们创建一个包含所有的3叠加在一起的张量。我们已经知道如何创建一个包含单个图像的张量。为了创建包含目录中所有图像的张量，我们首先使用Python列表推导式来创建单个图像张量的普通列表。\n",
    "\n",
    "在此过程中，我们将使用Jupyter对我们的工作做一些小检查——在本例中，确保返回的项目数量看起来合理:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tRdpcRoosoQJ",
    "outputId": "ba625e5a-f130-4bdf-df4c-e200450c8c75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMDZNgf4soQK"
   },
   "source": [
    "> note: List Comprehensions: List and dictionary comprehensions are a wonderful feature of Python. Many Python programmers use them every day, including the authors of this book—they are part of \"idiomatic Python.\" But programmers coming from other languages may have never seen them before. There are a lot of great tutorials just a web search away, so we won't spend a long time discussing them now. Here is a quick explanation and example to get you started. A list comprehension looks like this: `new_list = [f(o) for o in a_list if o>0]`. This will return every element of `a_list` that is greater than 0, after passing it to the function `f`. There are three parts here: the collection you are iterating over (`a_list`), an optional filter (`if o>0`), and something to do to each element (`f(o)`). It's not only shorter to write but way faster than the alternative ways of creating the same list with a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU9rjxHyx9qK"
   },
   "source": [
    ">注意:列表推导式:列表和字典推导式是Python的一个很棒的特性。许多Python程序员每天都在使用它们，包括本书的作者——它们是“惯用Python”的一部分。但是来自其他语言的程序员可能从未见过它们。有很多很棒的教程只需在网上搜索一下，所以我们现在不会花很长时间讨论它们。这是一个快速的解释和示例，可帮助您入门。列表推导式是这样的:`new_list = [f(o) for o in a_list if o>0]`。这将返回`a_list`中所有大于0的元素，并将其传递给函数`f`。这里有三个部分:正在迭代的集合(`a_list`)，一个可选的过滤器(`if o>0`)，以及对每个元素执行的操作(`f(o)`)。它不仅写起来更短，而且比使用循环创建相同列表的其他方法更快。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FavCNDiEsoQK"
   },
   "source": [
    "We'll also check that one of the images looks okay. Since we now have tensors (which Jupyter by default will print as values), rather than PIL images (which Jupyter by default will display as images), we need to use fastai's `show_image` function to display it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BOoiwc0yBzj"
   },
   "source": [
    "我们还将检查其中一张图像是否正常。由于我们现在有张量(Jupyter默认将打印为值)，而不是PIL图像(Jupyter默认将显示为图像)，我们需要使用fastai的`show_image`函数来显示它:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DtPSE-BZsoQK",
    "outputId": "b9890ce0-9df0-4b11-caf6-bceeaa7c0b4a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8Y2yTSssoQL"
   },
   "source": [
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. To do this we first combine all the images in this list into a single three-dimensional tensor. The most common way to describe such a tensor is to call it a *rank-3 tensor*. We often need to stack up individual tensors in a collection into a single tensor. Unsurprisingly, PyTorch comes with a function called `stack` that we can use for this purpose.\n",
    "\n",
    "Some operations in PyTorch, such as taking a mean, require us to *cast* our integer types to float types. Since we'll be needing this later, we'll also cast our stacked tensor to `float` now. Casting in PyTorch is as simple as typing the name of the type you wish to cast to, and treating it as a method.\n",
    "\n",
    "Generally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMREn-v8yFwj"
   },
   "source": [
    "对于每个像素位置，我们要计算该像素强度的所有图像的平均值。为了做到这一点，我们首先把这个列表中的所有图像合并成一个三维张量。描述这种张量最常见的方法是称它为*秩3 张量*。我们经常需要把集合中的单个张量叠加成一个张量。不出所料，PyTorch附带了一个名为`stack`的函数，我们可以使用它来实现这个目的。\n",
    "\n",
    "PyTorch中的一些操作，例如取平均值，需要将整型*转换*为浮点型。由于我们之后会需要它，所以我们现在也要把叠加的张量转换为`float`。在 PyTorch 中进行转换非常简单，只需键入您希望转换为的类型的名称，然后将其作为一个方法来处理。\n",
    "\n",
    "一般情况下，当图像是浮点数时，像素值应该在0到1之间，所以这里我们也将除以255："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ix1t_d8MsoQL",
    "outputId": "8b2318f9-48e2-4d4a-f995-d7c8a640f6bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXBVF8WbsoQM"
   },
   "source": [
    "Perhaps the most important attribute of a tensor is its *shape*. This tells you the length of each axis. In this case, we can see that we have 6,131 images, each of size 28×28 pixels. There is nothing specifically about this tensor that says that the first axis is the number of images, the second is the height, and the third is the width—the semantics of a tensor are entirely up to us, and how we construct it. As far as PyTorch is concerned, it is just a bunch of numbers in memory.\n",
    "\n",
    "The *length* of a tensor's shape is its rank:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUkr7adsyKfs"
   },
   "source": [
    "也许张量最重要的属性是它的*形状*。这告诉你每个轴的长度。在本例中，我们可以看到有6131张图片，每张图片的大小为28×28像素。关于这个张量，没有什么特别的东西表明第一个轴是图像的数量，第二个是高度，第三个是宽度——张量的语义完全取决于我们，以及我们如何构造它。就PyTorch而言，它只是内存中的一堆数字。\n",
    "\n",
    "张量形状的*长度*就是它的秩:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QIpb0GeEsoQM",
    "outputId": "c4073159-6bfa-4bf9-8e9d-3544ce8ec70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_threes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2cB1cHasoQM"
   },
   "source": [
    "It is really important for you to commit to memory and practice these bits of tensor jargon: _rank_ is the number of axes or dimensions in a tensor; _shape_ is the size of each axis of a tensor.\n",
    "\n",
    "> A: Watch out because the term \"dimension\" is sometimes used in two ways. Consider that we live in \"three-dimensonal space\" where a physical position can be described by a 3-vector `v`. But according to PyTorch, the attribute `v.ndim` (which sure looks like the \"number of dimensions\" of `v`) equals one, not three! Why? Because `v` is a vector, which is a tensor of rank one, meaning that it has only one _axis_ (even if that axis has a length of three). In other words, sometimes dimension is used for the size of an axis (\"space is three-dimensional\"); other times, it is used for the rank, or the number of axes (\"a matrix has two dimensions\"). When confused, I find it helpful to translate all statements into terms of rank, axis, and length, which are unambiguous terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrUoWUvLyPNO"
   },
   "source": [
    "对你们来说，记住并练习这些张量术语真的很重要：_秩_是张量中轴或维的数量； _形状_ 是张量每个轴的大小。\n",
    "\n",
    ">A:要注意，因为“维度”这个词有时有两种用法。考虑到我们生活在“三维空间”中，物理位置可以用3-向量`v`来描述。但是根据PyTorch，属性`v.ndim`(看起来确实像`v`的“维数”)等于1，而不是3 !为什么?因为`v`是一个向量，它是一个秩为1的张量，这意味着它只有一个_轴_(即使该轴的长度是3)。换句话说，有时维度被用来表示轴的大小(“空间是三维的”)；其他时候，它是用于秩，或轴的数量(“一个矩阵有两个维度”)。当感到困惑时，我发现将所有的表述转换为秩、轴和长度是很有帮助的，这些都是明确的术语。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvwgkJ1UsoQN"
   },
   "source": [
    "We can also get a tensor's rank directly with `ndim`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eme5q-WNyVut"
   },
   "source": [
    "我们也可以通过`ndim`直接得到一个张量的秩:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PVDsL8zTsoQN",
    "outputId": "c6acf013-2602-45c6-8dbb-876a7935d95f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oXiWDjxsoQN"
   },
   "source": [
    "Finally, we can compute what the ideal 3 looks like. We calculate the mean of all the image tensors by taking the mean along dimension 0 of our stacked, rank-3 tensor. This is the dimension that indexes over all the images.\n",
    "\n",
    "In other words, for every pixel position, this will compute the average of that pixel over all images. The result will be one value for every pixel position, or a single image. Here it is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSR70pgLyadN"
   },
   "source": [
    "最后，我们可以计算出理想 3 的样子。我们通过沿堆叠的 秩3 张量的 0 维取平均值来计算所有图像张量的平均值。这是索引所有图像的维度。\n",
    "\n",
    "换句话说，对于每个像素位置，这将计算该像素在所有图像上的平均值。结果将是每个像素位置的一个值，或单个图像。这里是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "arXFkodLsoQO",
    "outputId": "8bbe89fa-7b00-495b-b46e-c155d83a01ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqKim0YWsoQO"
   },
   "source": [
    "According to this dataset, this is the ideal number 3! (You may not like it, but this is what peak number 3 performance looks like.) You can see how it's very dark where all the images agree it should be dark, but it becomes wispy and blurry where the images disagree. \n",
    "\n",
    "Let's do the same thing for the 7s, but put all the steps together at once to save some time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0MYhuYWygql"
   },
   "source": [
    "根据这个数据集，这是理想的数字3!(你可能不喜欢它，但这就是3号峰值性能的样子。)你可以看到，所有图像一致认为它应该是黑暗的地方，它是非常黑暗的，但在图像不一致的地方，它变得模糊不清。\n",
    "\n",
    "让我们对7s做同样的事情，但将所有步骤放在一起以节省一些时间:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BE3nQy_7soQO",
    "outputId": "74cfe101-31de-4d64-9795-6d42fac6f50d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpTU12KJsoQP"
   },
   "source": [
    "Let's now pick an arbitrary 3 and measure its *distance* from our \"ideal digits.\"\n",
    "\n",
    "> stop: Stop and Think!: How would you calculate how similar a particular image is to each of our ideal digits? Remember to step away from this book and jot down some ideas before you move on! Research shows that recall and understanding improves dramatically when you are engaged with the learning process by solving problems, experimenting, and trying new ideas yourself\n",
    "\n",
    "Here's a sample 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UABCegChyk9j"
   },
   "source": [
    "现在我们任意选一个3，然后测量它与“理想数字”的*距离*。\n",
    "\n",
    ">停:停下来想想！:你如何计算特定的图像与我们每个理想数字的相似程度?在继续之前，记得离开这本书并记下一些想法！研究表明，当你通过自己解决问题、试验和尝试新想法来参与学习过程时，记忆力和理解力会显著提高\n",
    "\n",
    "这是一个样本 3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QgeovTcPsoQP",
    "outputId": "bda4bb86-cd13-4125-e303-ee7c83a367ed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtm39MlDsoQQ"
   },
   "source": [
    "How can we determine its distance from our ideal 3? We can't just add up the differences between the pixels of this image and the ideal digit. Some differences will be positive while others will be negative, and these differences will cancel out, resulting in a situation where an image that is too dark in some places and too light in others might be shown as having zero total differences from the ideal. That would be misleading!\n",
    "\n",
    "To avoid this, there are two main ways data scientists measure distance in this context:\n",
    "\n",
    "- Take the mean of the *absolute value* of differences (absolute value is the function that replaces negative values with positive values). This is called the *mean absolute difference* or *L1 norm*\n",
    "- Take the mean of the *square* of differences (which makes everything positive) and then take the *square root* (which undoes the squaring). This is called the *root mean squared error* (RMSE) or *L2 norm*.\n",
    "\n",
    "> important: It's Okay to Have Forgotten Your Math: In this book we generally assume that you have completed high school math, and remember at least some of it... But everybody forgets some things! It all depends on what you happen to have had reason to practice in the meantime. Perhaps you have forgotten what a _square root_ is, or exactly how they work. No problem! Any time you come across a maths concept that is not explained fully in this book, don't just keep moving on; instead, stop and look it up. Make sure you understand the basic idea, how it works, and why we might be using it. One of the best places to refresh your understanding is Khan Academy. For instance, Khan Academy has a great [introduction to square roots](https://www.khanacademy.org/math/algebra/x2f8bb11595b61c86:rational-exponents-radicals/x2f8bb11595b61c86:radicals/v/understanding-square-roots)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V2ruQs4yrZn"
   },
   "source": [
    "我们如何确定它与理想3的距离?我们不能仅仅把这张图像的像素和理想数字之间的差异加起来。有些差异是正的，而有些是负的，这些差异会相互抵消，导致图像在某些地方太暗而在另一些地方太亮，可能会显示为与理想数字的总差异为零。那将是误导！\n",
    "\n",
    "\n",
    "为了避免这种情况，数据科学家在这种情况下测量距离有两种主要方式：\n",
    "\n",
    "- 取差值*绝对值*的平均值(绝对值是用正值代替负值的函数)。这叫做*平均绝对差*或*L1范数*\n",
    "- 取差值*平方*的均值(使所有值都是正的)，然后取*平方根*(抵消平方)这叫做*均方根误差*(RMSE)或*L2范数*。\n",
    "\n",
    ">重要：忘记你的数学也没关系：在这本书中，我们通常假设你已经完成了高中的数学课程，并且至少记住了一部分……但是每个人都会忘记一些事情！这完全取决于你碰巧在此期间有理由练习了什么。也许你已经忘记了什么是 _平方根_ ，或者它们到底是如何起作用的。没问题！每当你遇到本书未充分解释的数学概念时，不要只是继续看下去;相反，停下来查一查。确保你理解了它的基本思想，它是如何工作的，以及我们为什么要使用它。刷新您的理解的最佳场所之一是可汗学院。例如，可汗学院[对平方根有很好的介绍](https://www.khanacademy.org/math/algebra/x2f8bb11595b61c86:rational-exponents-radicals/x2f8bb11595b61c86:radicals/v/understanding-square-roots)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be1I0luOsoQQ"
   },
   "source": [
    "Let's try both of these now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwymgn9byzG2"
   },
   "source": [
    "现在让我们尝试这两种方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9K-7DWSQsoQQ",
    "outputId": "bc5fa72c-2ea7-4cd5-d2fe-d8b6ce4180c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = (a_3 - mean3).abs().mean()\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7tgKIR6psoQR",
    "outputId": "9e9f4e9c-d3f4-44cf-c92f-ee953f0e42c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_7_abs = (a_3 - mean7).abs().mean()\n",
    "dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\n",
    "dist_7_abs,dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAKDifWSsoQR"
   },
   "source": [
    "In both cases, the distance between our 3 and the \"ideal\" 3 is less than the distance to the ideal 7. So our simple model will give the right prediction in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYa2KcRxy24f"
   },
   "source": [
    "在这两种情况下，3到“理想”3的距离都小于到理想7的距离。所以我们的简单模型会给出正确的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QA28GonbsoQS"
   },
   "source": [
    "PyTorch already provides both of these as *loss functions*. You'll find these inside `torch.nn.functional`, which the PyTorch team recommends importing as `F` (and is available by default under that name in fastai):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tJFhiety6GO"
   },
   "source": [
    "PyTorch已经将这两个函数作为*损失函数*提供。你可以在`torch.nn.functional`中找到这些。PyTorch团队建议将其导入为`F` (并且在fastai中默认使用该名称):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TacgUSc1soQT",
    "outputId": "9baa15e2-995e-4cbe-8493-85c1556d0bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl8d0KcysoQU"
   },
   "source": [
    "Here `mse` stands for *mean squared error*, and `l1` refers to the standard mathematical jargon for *mean absolute value* (in math it's called the *L1 norm*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_C8xBtwy9xm"
   },
   "source": [
    "这里`mse`代表*均方误差*，`l1`指的是*平均绝对值*的标准数学术语(在数学中称为*L1范数*)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6RwJYRZsoQW"
   },
   "source": [
    "> S: Intuitively, the difference between L1 norm and mean squared error (MSE) is that the latter will penalize bigger mistakes more heavily than the former (and be more lenient with small mistakes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDH7DW1XzCCI"
   },
   "source": [
    ">S:直观上，L1范数和均方误差(MSE) 的区别在于后者会比前者更严厉地惩罚更大的错误（并且对小错误更宽容）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPn4p5OLsoQX"
   },
   "source": [
    "> J: When I first came across this \"L1\" thingie, I looked it up to see what on earth it meant. I found on Google that it is a _vector norm_ using _absolute value_, so looked up _vector norm_ and started reading: _Given a vector space V over a field F of the real or complex numbers, a norm on V is a nonnegative-valued any function p: V → \\[0,+∞) with the following properties: For all a ∈ F and all u, v ∈ V, p(u + v) ≤ p(u) + p(v)..._ Then I stopped reading. \"Ugh, I'll never understand math!\" I thought, for the thousandth time. Since then I've learned that every time these complex mathy bits of jargon come up in practice, it turns out I can replace them with a tiny bit of code! Like, the _L1 loss_ is just equal to `(a-b).abs().mean()`, where `a` and `b` are tensors. I guess mathy folks just think differently than me... I'll make sure in this book that every time some mathy jargon comes up, I'll give you the little bit of code it's equal to as well, and explain in common-sense terms what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up59GEnUzF-z"
   },
   "source": [
    ">J:当我第一次看到“L1”这个词的时候，我就查了一下，想知道它到底是什么意思。我在谷歌上发现它是一个使用_绝对值_的_向量范数_ ，所以查找_向量范数_ 并开始阅读: _给定一个实数或复数域F上的向量空间V, V上的范数是一个非负值的任意函数p: V→[0，+∞），具有以下性质：对于所有a∈F和所有u, v∈V, p(u + v)≤p(u) + p(v)..._ 然后我就不读了。我无数次地想“啊，我永远都不懂数学了!”。从那以后，我学会了每次在实践中出现这些复杂的数学术语时，我都可以用一小段代码来替换它们！比如， _L1损失_ 就等于`(a-b).abs().mean()`，其中`a`和`b`是张量。我想数学家的想法和我的不一样…我会确保在这本书中，每次出现一些数学术语，我会给出它等于的代码，然后用常识性的术语解释发生了什么。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lMdxUhssoQX"
   },
   "source": [
    "We just completed various mathematical operations on PyTorch tensors. If you've done some numeric programming in NumPy before, you may recognize these as being similar to NumPy arrays. Let's have a look at those two very important data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmxjpbvFzLh_"
   },
   "source": [
    "我们刚刚完成了对PyTorch张量的各种数学运算。如果您以前使用NumPy进行过一些数值编程，那么您可能会认为这些类似于NumPy数组。让我们来看看这两个非常重要的数据结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWur3woCsoQX"
   },
   "source": [
    "### NumPy Arrays and PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxYMQPi8Lsfc"
   },
   "source": [
    "### NumPy数组和PyTorch张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM-XcD_SsoQY"
   },
   "source": [
    "[NumPy](https://numpy.org/) is the most widely used library for scientific and numeric programming in Python. It provides very similar functionality and a very similar API to that provided by PyTorch; however, it does not support using the GPU or calculating gradients, which are both critical for deep learning. Therefore, in this book we will generally use PyTorch tensors instead of NumPy arrays, where possible.\n",
    "\n",
    "(Note that fastai adds some features to NumPy and PyTorch to make them a bit more similar to each other. If any code in this book doesn't work on your computer, it's possible that you forgot to include a line like this at the start of your notebook: `from fastai.vision.all import *`.)\n",
    "\n",
    "But what are arrays and tensors, and why should you care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJM8RdOPLzKy"
   },
   "source": [
    "[NumPy](https://numpy.org/)是Python 中使用最广泛的科学和数值编程库。它提供了与PyTorch非常相似的功能和API；但是，它不支持使用GPU或计算梯度，这两个都是深度学习的关键。因此，在本书中，我们通常会尽可能地使用PyTorch张量而不是NumPy数组。\n",
    "\n",
    "(注意fastai为NumPy和PyTorch添加了一些功能，使它们彼此更加相似。如果这本书中的任何代码在你的电脑上不起作用，你可能忘记在你的笔记本的开头包括这样的一行:`from fastai.vision.all import *`。)\n",
    "\n",
    "但是什么是数组和张量，为什么要关心这些呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM1GIrsFsoQY"
   },
   "source": [
    "Python is slow compared to many languages. Anything fast in Python, NumPy, or PyTorch is likely to be a wrapper for a compiled object written (and optimized) in another language—specifically C. In fact, **NumPy arrays and PyTorch tensors can finish computations many thousands of times faster than using pure Python.**\n",
    "\n",
    "A NumPy array is a multidimensional table of data, with all items of the same type. Since that can be any type at all, they can even be arrays of arrays, with the innermost arrays potentially being different sizes—this is called a \"jagged array.\" By \"multidimensional table\" we mean, for instance, a list (dimension of one), a table or matrix (dimension of two), a \"table of tables\" or \"cube\" (dimension of three), and so forth. If the items are all of some simple type such as integer or float, then NumPy will store them as a compact C data structure in memory. This is where NumPy shines. NumPy has a wide variety of operators and methods that can run computations on these compact structures at the same speed as optimized C, because they are written in optimized C.\n",
    "\n",
    "A PyTorch tensor is nearly the same thing as a NumPy array, but with an additional restriction that unlocks some additional capabilities. It's the same in that it, too, is a multidimensional table of data, with all items of the same type. However, the restriction is that a tensor cannot use just any old type—it has to use a single basic numeric type for all components. For example, a PyTorch tensor cannot be jagged. It is always a regularly shaped multidimensional rectangular structure.\n",
    "\n",
    "The vast majority of methods and operators supported by NumPy on these structures are also supported by PyTorch, but PyTorch tensors have additional capabilities. One major capability is that these structures can live on the GPU, in which case their computation will be optimized for the GPU and can run much faster (given lots of values to work on). In addition, PyTorch can automatically calculate derivatives of these operations, including combinations of operations. As you'll see, it would be impossible to do deep learning in practice without this capability.\n",
    "\n",
    "> S: If you don't know what C is, don't worry as you won't need it at all. In a nutshell, it's a low-level  (low-level means more similar to the language that computers use internally) language that is very fast compared to Python. To take advantage of its speed while programming in Python, try to avoid as much as possible writing loops, and replace them by commands that work directly on arrays or tensors.\n",
    "\n",
    "Perhaps the most important new coding skill for a Python programmer to learn is how to effectively use the array/tensor APIs. We will be showing lots more tricks later in this book, but here's a summary of the key things you need to know for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtMjDdwMMHLS"
   },
   "source": [
    "与许多语言相比，Python是缓慢的。Python、NumPy或PyTorch中任何快速的东西都可能是用另一种语言(特别是c)编写(并优化)的编译对象的包装器。事实上，**NumPy数组和PyTorch张量完成计算的速度比使用纯Python快数千倍**。\n",
    "\n",
    "NumPy数组是一个多维数据表，所有项都是相同类型的。因为它可以是任何类型，它们甚至可以是数组的数组，最里面的数组可能有不同的大小——这被称为“锯齿状数组”。例如，一个列表（一维）、一个表或矩阵（二维）、一个“表的表”或“立方体”（三维）等等。如果项目都是一些简单类型，比如整型或浮点型，那么NumPy将它们作为紧凑的C数据结构存储在内存中。这就是NumPy大放异彩的地方。NumPy有各种各样的运算符和方法，可以以与优化的 C 相同的速度在这些紧凑结构上运行计算，因为它们是用优化的C编写的。\n",
    "\n",
    "PyTorch张量几乎与NumPy数组相同，但有一个额外的限制，可以解锁一些额外的功能。它的相同之处在于，它也是一个多维数据表，所有项都是相同类型的。然而，限制是张量不能仅仅使用任何旧类型——它必须对所有分量使用单一的基本数字类型。例如，PyTorch张量不能是锯齿状的。它总是一个规则形状的多维矩形结构。\n",
    "\n",
    "PyTorch也支持NumPy在这些结构上支持的绝大多数方法和操作符，但PyTorch 张量具有额外的功能。一个主要的功能是这些结构可以在GPU上运行，在这种情况下，它们的计算针对 GPU 进行优化，并且可以运行得更快（给定大量的工作值）。此外，PyTorch可以自动计算这些操作的导数，包括操作的组合。正如你将看到的，在实践中，如果没有这种能力，就不可能在实践中进行深度学习。\n",
    "\n",
    ">S:如果你不知道C是什么，别担心，因为你根本不需要它。简而言之，它是一种低级(低级意味着更类似于计算机内部使用的语言)语言，与Python相比速度非常快。为了在使用 Python 编程时利用它的速度，请尽量避免编写循环，并用直接在数组或张量上工作的命令替换它们。\n",
    "\n",
    "对于Python程序员来说，最重要的新编码技能可能是如何有效地使用数组/张量 API。我们将在本书后面展示更多的技巧，但这里是你现在需要知道的关键事情的总结。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvQ5pdv3soQY"
   },
   "source": [
    "To create an array or tensor, pass a list (or list of lists, or list of lists of lists, etc.) to `array()` or `tensor()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk4138GaNVJA"
   },
   "source": [
    "要创建数组或张量，请将列表(或列表的列表，或列表的列表的列表等)传递给`array()`或`tensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bQh3cQtLsoQZ"
   },
   "outputs": [],
   "source": [
    "data = [[1,2,3],[4,5,6]]\n",
    "arr = array (data)\n",
    "tns = tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bEJvVV7LsoQZ",
    "outputId": "08f9b2d3-50ee-4415-867b-adac538767e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr  # numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GKeH6ix0soQa",
    "outputId": "88be0d23-ba4d-4a37-a378-d28942f2ae81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns  # pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5UQgWGosoQa"
   },
   "source": [
    "All the operations that follow are shown on tensors, but the syntax and results for NumPy arrays is identical.\n",
    "\n",
    "You can select a row (note that, like lists in Python, tensors are 0-indexed so 1 refers to the second row/column):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6NGbj5nOgE4"
   },
   "source": [
    "接下来的所有操作都显示在张量上，但NumPy数组的语法和结果是相同的。\n",
    "\n",
    "你可以选择一行(注意，与Python中的列表一样，张量是0索引的，所以1指的是第二行/列):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2klbZLKpsoQa",
    "outputId": "3fb7d4d6-7113-400f-a8fd-d2f914b03f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJv4IPZ-soQb"
   },
   "source": [
    "or a column, by using `:` to indicate *all of the first axis* (we sometimes refer to the dimensions of tensors/arrays as *axes*):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCwGr3M3OoAW"
   },
   "source": [
    "或者一列，用`:`表示*所有第一个轴*(我们有时把张量/数组的维度称为*轴*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xZJ36L56soQb",
    "outputId": "d1e52ff8-d290-499a-bb28-52ab9b1d8292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWR-z0EjsoQb"
   },
   "source": [
    "You can combine these with Python slice syntax (`[start:end]` with `end` being excluded) to select part of a row or column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2PA4Pj5OwVd"
   },
   "source": [
    "你可以将这些与Python切片语法(`[start:end]`， `end`被排除)相结合来选择行或列的一部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WKdZujlAsoQc",
    "outputId": "9bcf94f6-3266-4202-dfa3-8d7ca880562e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdWkjwa8soQc"
   },
   "source": [
    "And you can use the standard operators such as `+`, `-`, `*`, `/`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkdSDIYEO4uj"
   },
   "source": [
    "你可以使用标准运算符，如`+`，`-`，`*`，`/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lD2Dl1IUsoQc",
    "outputId": "0f513c5b-f0fd-4779-ab56-8b88cce0b06d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPaqlLpxsoQd"
   },
   "source": [
    "Tensors have a type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCSDohFvPAp_"
   },
   "source": [
    "张量有一种类型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tHOMCENUsoQd",
    "outputId": "b79ec0e1-2c4b-4937-e278-e3ecdb5ba360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCxBUSHLsoQe"
   },
   "source": [
    "And will automatically change type as needed, for example from `int` to `float`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TWQgM7sPEbo"
   },
   "source": [
    "并且会根据需要自动更改类型，例如从`int`到`float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4FdkHdOQsoQe",
    "outputId": "ae6ebc24-b5ad-4cea-cbf1-9fd95836978a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 3.0000, 4.5000],\n",
       "        [6.0000, 7.5000, 9.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lOOpu0asoQe"
   },
   "source": [
    "So, is our baseline model any good? To quantify this, we must define a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNHKDvtuPKog"
   },
   "source": [
    "那么，我们的基线模型好吗?为了量化这一点，我们必须定义一个指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VPA6I1-soQf"
   },
   "source": [
    "## Computing Metrics Using Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY-oXVZiPPhD"
   },
   "source": [
    "## 使用广播计算指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMrSOc2xsoQf"
   },
   "source": [
    "Recall that a metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset, in order to tell us how good our model is. For instance, we could use either of the functions we saw in the previous section, mean squared error, or mean absolute error, and take the average of them over the whole dataset. However, neither of these are numbers that are very understandable to most people; in practice, we normally use *accuracy* as the metric for classification models.\n",
    "\n",
    "As we've discussed, we want to calculate our metric over a *validation set*. This is so that we don't inadvertently overfit—that is, train a model to work well only on our training data. This is not really a risk with the pixel similarity model we're using here as a first try, since it has no trained components, but we'll use a validation set anyway to follow normal practices and to be ready for our second try later.\n",
    "\n",
    "To get a validation set we need to remove some of the data from training entirely, so it is not seen by the model at all. As it turns out, the creators of the MNIST dataset have already done this for us. Do you remember how there was a whole separate directory called *valid*? That's what this directory is for!\n",
    "\n",
    "So to start with, let's create tensors for our 3s and 7s from that directory. These are the tensors we will use to calculate a metric measuring the quality of our first-try model, which measures distance from an ideal image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvoMTM-BPT1o"
   },
   "source": [
    "回想一下，指标是根据我们的模型的预测和数据集中的正确标签计算得出的数字，以告诉我们我们的模型有多好。例如，我们可以使用我们在上一节中看到的任何一个函数，均方误差或平均绝对误差，并在整个数据集中取它们的平均值。然而，这两个数字对大多数人来说都不是很容易理解的;在实践中，我们通常使用*准确率*作为分类模型的指标。\n",
    "\n",
    "正如我们所讨论的，我们希望在*验证集*上计算我们的指标。这样我们就不会无意中过度拟合——也就是说，训练一个模型只在我们的训练数据上运行良好。对于我们在这里作为第一次尝试使用的像素相似度模型来说，这并不是真正的风险，因为它没有经过训练的组件，但无论如何我们都会使用验证集来遵循正常的做法，并为以后的第二次尝试做好准备。\n",
    "\n",
    "要获得验证集，我们需要从训练中完全删除一些数据，因此模型根本看不到它。事实证明，MNIST数据集的创建者已经为我们完成了这件事。您还记得如何有一个完整的单独目录称为*valid*吗？这就是这个目录的用途！\n",
    "\n",
    "所以首先，让我们从该目录为我们的3s和7s创建张量。这些张量将用于计算衡量我们的第一次尝试模型质量的指标，该模型测量与理想图像的距离："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "TMPO5Si4soQf",
    "outputId": "0f01eacf-51f0-4612-9daa-73add6aa0323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhQO37nmsoQh"
   },
   "source": [
    "It's good to get in the habit of checking shapes as you go. Here we see two tensors, one representing the 3s validation set of 1,010 images of size 28×28, and one representing the 7s validation set of 1,028 images of size 28×28.\n",
    "\n",
    "We ultimately want to write a function, `is_3`, that will decide if an arbitrary image is a 3 or a 7. It will do this by deciding which of our two \"ideal digits\" this arbitrary image is closer to. For that we need to define a notion of distance—that is, a function that calculates the distance between two images.\n",
    "\n",
    "We can write a simple function that calculates the mean absolute error using an expression very similar to the one we wrote in the last section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVsGw0AoPbFE"
   },
   "source": [
    "养成检查形状的习惯是很好的。这里我们看到两个张量，一个代表 1,010 张 28×28 图像的 3s 验证集，一个代表 1,028 张 28×28 图像的 7s 验证集。\n",
    "\n",
    "我们最终想写一个函数，`is_3`，来决定任意图像是3还是7。它将通过确定任意图像与两个“理想数字”中的哪一个更接近来实现这一点。为此，我们需要定义一个距离的概念——即计算两幅图像之间距离的函数。\n",
    "\n",
    "我们可以编写一个简单的函数，使用与我们在上一节中编写的表达式非常相似的表达式来计算平均绝对误差:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "w45NeHOysoQi",
    "outputId": "97bb3c71-1974-4ed4-ca7f-3abb31a4e159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJiRsNO4soQj"
   },
   "source": [
    "This is the same value we previously calculated for the distance between these two images, the ideal 3 `mean3` and the arbitrary sample 3 `a_3`, which are both single-image tensors with a shape of `[28,28]`.\n",
    "\n",
    "But in order to calculate a metric for overall accuracy, we will need to calculate the distance to the ideal 3 for _every_ image in the validation set. How do we do that calculation? We could write a loop over all of the single-image tensors that are stacked within our validation set tensor, `valid_3_tens`, which has a shape of `[1010,28,28]` representing 1,010 images. But there is a better way.\n",
    "\n",
    "Something very interesting happens when we take this exact same distance function, designed for comparing two single images, but pass in as an argument `valid_3_tens`, the tensor that represents the 3s validation set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZw_wHAkPh5z"
   },
   "source": [
    "这与我们之前为这两个图像之间的距离计算的值相同，理想的3`mean3`和任意的样本3`a_3`，它们都是形状为`[28,28]`的单图像张量。\n",
    "\n",
    "但是为了计算整体准确度的指标，我们需要计算验证集中 _每个_ 图像到理想3的距离。我们怎么计算呢?我们可以对堆叠在我们的验证集张量中的所有单张图像张量编写一个循环`valid_3_tens`，它的形状`[1010,28,28]`，表示1010张图像。但是有一个更好的方法。\n",
    "\n",
    "当我们使用这个完全相同的距离函数时，会发生非常有趣的事情，这个距离函数是为比较两个单张图像而设计的，但作为参数传入`valid_3_tens`，表示 3s 验证集的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "z2Wk_Y47soQj",
    "outputId": "2b10518b-422c-4701-e7b5-1d9193843785"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1280, 0.1623, 0.1242,  ..., 0.1508, 0.1263, 0.1260]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8mQNXWgsoQk"
   },
   "source": [
    "Instead of complaining about shapes not matching, it returned the distance for every single image as a vector (i.e., a rank-1 tensor) of length 1,010 (the number of 3s in our validation set). How did that happen?\n",
    "\n",
    "Take another look at our function `mnist_distance`, and you'll see we have there the subtraction `(a-b)`. The magic trick is that PyTorch, when it tries to perform a simple subtraction operation between two tensors of different ranks, will use *broadcasting*. That is, it will automatically expand the tensor with the smaller rank to have the same size as the one with the larger rank. Broadcasting is an important capability that makes tensor code much easier to write.\n",
    "\n",
    "After broadcasting so the two argument tensors have the same rank, PyTorch applies its usual logic for two tensors of the same rank: it performs the operation on each corresponding element of the two tensors, and returns the tensor result. For instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZMGC4DjRFsl"
   },
   "source": [
    "它没有抱怨形状不匹配，而是将每幅图像的距离作为长度为1010(验证集中3的个数)的向量(即秩1张量)返回。这是怎么发生的?\n",
    "\n",
    "再看一下我们的函数`mnist_distance`，你会发现我们有减法`(a-b)`。PyTorch的神奇之处在于，当它试图在两个不同秩的张量之间执行一个简单的减法运算时，将使用*广播*。也就是说，它会自动扩展秩较小的张量，使其与秩较大的张量具有相同的大小。广播是一种重要的能力，它使张量代码更容易编写。\n",
    "\n",
    "广播后，两个参数张量具有相同的秩，PyTorch 将其通常的逻辑应用于相同秩的两个张量：它对两个张量的每个对应元素执行操作，并返回张量结果。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mfoT2Hn0soQk",
    "outputId": "c6a0a34b-3c9b-4626-ac09-463f932a4aa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1,2,3]) + tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ-AS9rUsoQk"
   },
   "source": [
    "So in this case, PyTorch treats `mean3`, a rank-2 tensor representing a single image, as if it were 1,010 copies of the same image, and then subtracts each of those copies from each 3 in our validation set. What shape would you expect this tensor to have? Try to figure it out yourself before you look at the answer below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJvxJBo-RPDP"
   },
   "source": [
    "因此，在这种情况下，PyTorch 将`mean3`表示单个图像的 秩2 张量视为同一图像的 1,010 个副本，然后用验证集中的每个3减去这些副本。你希望这个张量有什么形状?在查看以下答案之前，请尝试自己弄清楚："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LEBEqZsksoQl",
    "outputId": "b36386f4-0cdc-4053-cec9-8c68120cd0d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_3_tens-mean3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kok5eDvDsoQl"
   },
   "source": [
    "We are calculating the difference between our \"ideal 3\" and each of the 1,010 3s in the validation set, for each of 28×28 images, resulting in the shape `[1010,28,28]`.\n",
    "\n",
    "There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:\n",
    "\n",
    "- PyTorch doesn't *actually* copy `mean3` 1,010 times. It *pretends* it were a tensor of that shape, but doesn't actually allocate any additional memory\n",
    "- It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).\n",
    "\n",
    "This is true of all broadcasting and elementwise operations and functions done in PyTorch. *It's the most important technique for you to know to create efficient PyTorch code.*\n",
    "\n",
    "Next in `mnist_distance` we see `abs`. You might be able to guess now what this does when applied to a tensor. It applies the method to each individual element in the tensor, and returns a tensor of the results (that is, it applies the method \"elementwise\"). So in this case, we'll get back 1,010 matrices of absolute values.\n",
    "\n",
    "Finally, our function calls `mean((-1,-2))`. The tuple `(-1,-2)` represents a range of axes. In Python, `-1` refers to the last element, and `-2` refers to the second-to-last. So in this case, this tells PyTorch that we want to take the mean ranging over the values indexed by the last two axes of the tensor. The last two axes are the horizontal and vertical dimensions of an image. After taking the mean over the last two axes, we are left with just the first tensor axis, which indexes over our images, which is why our final size was `(1010)`. In other words, for every image, we averaged the intensity of all the pixels in that image.\n",
    "\n",
    "We'll be learning lots more about broadcasting throughout this book, especially in <<chapter_foundations>>, and will be practicing it regularly too.\n",
    "\n",
    "We can use `mnist_distance` to figure out whether an image is a 3 or not by using the following logic: if the distance between the digit in question and the ideal 3 is less than the distance to the ideal 7, then it's a 3. This function will automatically do broadcasting and be applied elementwise, just like all PyTorch functions and operators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfxTBdMqRXme"
   },
   "source": [
    "我们正在计算我们的“理想3”和验证集中的1,010个3之间的差异，对于每个28×28图片，得到的形状为`[1010,28,28]`。\n",
    "\n",
    "关于广播是如何实现的，有几个要点，这使得它不仅在表现力上有价值，而且在性能上也有价值：\n",
    "\n",
    "- PyTorch*实际上*并没有复制`mean3` 1,010次。它*假装*它是那种形状的张量，但实际上并不分配任何额外的内存\n",
    "- 它以C（或者，如果您使用的是GPU，则在CUDA中，相当于GPU上的C）完成整个计算，比纯Python快数万倍(在GPU上快数百万倍!)\n",
    "\n",
    "在 PyTorch 中完成的所有广播和元素操作和函数都是如此。*这是创建高效 PyTorch 代码的最重要技术。*\n",
    "\n",
    "接下来在`mnist_distance`中我们看到了`abs`。现在你可能已经猜到当它应用于一个张量时会发生什么。它将该方法应用于张量中的每个单独元素，并返回结果的张量(即，它“按元素”应用方法)。所以在这种情况下，我们将得到 1,010 个绝对值矩阵。\n",
    "\n",
    "最后，我们的函数调用`mean((-1，-2))`。元组`(-1，-2)`表示轴的范围。在Python中，`-1`表示最后一个元素，`-2`表示倒数第二个元素。所以在这种情况下，这告诉PyTorch我们希望在张量的最后两个轴索引的值上取平均值范围。最后两个轴是图像的水平和垂直维度。在对最后两个轴取平均值后，我们只剩下第一个张量轴，它对我们的图像进行索引，这就是为什么我们的最终大小是`（1010）`。换句话说，对于每张图像，我们平均了该图像中所有像素的强度。\n",
    "\n",
    "通过这本书，我们将学到更多关于广播的知识，尤其是在<<chapter_foundations>>中，我们还会定期练习。\n",
    "\n",
    "我们可以使用`mnist_distance`通过以下逻辑来判断一张图像是否为3:如果所讨论数字和理想3之间的距离小于与理想7之间的距离，那么它就是3。此函数将自动进行广播并按元素应用，就像所有PyTorch函数和运算符一样:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "CBk4fwZwsoQm"
   },
   "outputs": [],
   "source": [
    "def is_3(x): return mnist_distance(x,mean3) < mnist_distance(x,mean7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhaldFAZsoQm"
   },
   "source": [
    "Let's test it on our example case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkAfybumSGhF"
   },
   "source": [
    "让我们在我们的示例案例中测试它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "r6yfFpE-soQn",
    "outputId": "319b0871-7f0f-495c-d2c1-ac8c01e70388"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPvuF0xbsoQn"
   },
   "source": [
    "Note that when we convert the Boolean response to a float, we get `1.0` for `True` and `0.0` for `False`. Thanks to broadcasting, we can also test it on the full validation set of 3s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6CXdhp_SQsY"
   },
   "source": [
    "请注意，当我们将布尔响应转换为浮点数时，`True`为`1.0`，`False`为`0.0`。得益于广播，我们还可以在3s的完整验证集上测试它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "f5dHVIBSsoQo",
    "outputId": "69433330-c742-417c-fe77-fc6d731d9340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVfzaI-LsoQp"
   },
   "source": [
    "Now we can calculate the accuracy for each of the 3s and 7s by taking the average of that function for all 3s and its inverse for all 7s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTpIRYoZSZCi"
   },
   "source": [
    "现在我们可以通过对所有 3 取该函数的平均值及对所有 7 取反的函数的平均值来计算每个 3 和 7 的准确度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nZSgyBcsoQp",
    "outputId": "37e64bf3-1b7f-4b75-9541-403bf2ce4df0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3s =      is_3(valid_3_tens).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIPBTCwosoQr"
   },
   "source": [
    "This looks like a pretty good start! We're getting over 90% accuracy on both 3s and 7s, and we've seen how to define a metric conveniently using broadcasting.\n",
    "\n",
    "But let's be honest: 3s and 7s are very different-looking digits. And we're only classifying 2 out of the 10 possible digits so far. So we're going to need to do better!\n",
    "\n",
    "To do better, perhaps it is time to try a system that does some real learning—that is, that can automatically modify itself to improve its performance. In other words, it's time to talk about the training process, and SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtvt8b5GSd0t"
   },
   "source": [
    "这看起来是个不错的开始!我们在3s和7s上的准确率都超过了90%，并且我们已经了解了如何使用广播方便地定义指标。\n",
    "\n",
    "但说实话:3s和7s看起来是完全不同的数字。到目前为止，我们只对 10 个可能的数字中的 2 个进行分类。所以我们需要做得更好！\n",
    "\n",
    "为了做得更好，也许是时候尝试一个能够进行一些真正学习的系统了——也就是说，它可以自动修改自身以提高其性能。换句话说，是时候谈谈训练过程和SGD了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3o3HpnJsoQs"
   },
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3220FddFSkew"
   },
   "source": [
    "## 随机梯度下降(SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTdfIOrxsoQs"
   },
   "source": [
    "Do you remember the way that Arthur Samuel described machine learning, which we quoted in <<chapter_intro>>?\n",
    "\n",
    "> : Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.\n",
    "\n",
    "As we discussed, this is the key to allowing us to have a model that can get better and better—that can learn. But our pixel similarity approach does not really do this. We do not have any kind of weight assignment, or any way of improving based on testing the effectiveness of a weight assignment. In other words, we can't really improve our pixel similarity approach by modifying a set of parameters. In order to take advantage of the power of deep learning, we will first have to represent our task in the way that Arthur Samuel described it.\n",
    "\n",
    "Instead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one, such that the highest weights are associated with those pixels most likely to be black for a particular category. For instance, pixels toward the bottom right are not very likely to be activated for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8. This can be represented as a function and set of weight values for each possible category—for instance the probability of being the number 8:\n",
    "\n",
    "```\n",
    "def pr_eight(x,w): return (x*w).sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REbnmMKjSsfR"
   },
   "source": [
    "你还记得我们在<<chapter_intro>>中引用的Arthur Samuel描述机器学习的方式吗?\n",
    "\n",
    ">:假设我们安排一些自动方法来测试任何当前权重分配在实际性能方面的有效性，并提供一种改变权重分配的机制以最大化性能。我们不需要深入了解这样一个程序的细节，就可以看到它可以完全自动化，并看到这样编程的机器会从它的经验中“学习”。\n",
    "\n",
    "正如我们所讨论的，这是让我们拥有一个可以变得越来越好——可以学习的模型的关键。但是我们的像素相似度方法并不能真正做到这一点。我们没有任何类型的权重分配，也没有任何基于测试权重分配有效性的改进方式。换句话说，我们不能通过修改一组参数来真正改进我们的像素相似度方法。为了充分利用深度学习的力量，我们首先必须按照Arthur Samuel描述的方式来表示我们的任务。\n",
    "\n",
    "与其试图找到图像和“理想图像”之间的相似性，我们可以查看每个单独的像素并为每个像素提出一组权重，这样，最高的权重就与那些在特定类别中最有可能是黑色的像素相关联。例如，右下角的像素对于7不太可能被激活，所以它们对于7应该具有较低的权重，但对于8却可能被激活，所以它们对于8应该具有较高的权重。这可以表示为每个可能类别的函数和一组权重值——例如，成为数字8的概率:\n",
    "\n",
    "```\n",
    "def pr_eight(x,w): return (x*w).sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYMEM-PisoQt"
   },
   "source": [
    "Here we are assuming that `x` is the image, represented as a vector—in other words, with all of the rows stacked up end to end into a single long line. And we are assuming that the weights are a vector `w`. If we have this function, then we just need some way to update the weights to make them a little bit better. With such an approach, we can repeat that step a number of times, making the weights better and better, until they are as good as we can make them.\n",
    "\n",
    "We want to find the specific values for the vector `w` that causes the result of our function to be high for those images that are actually 8s, and low for those images that are not. Searching for the best vector `w` is a way to search for the best function for recognising 8s. (Because we are not yet using a deep neural network, we are limited by what our function can actually do—we are going to fix that constraint later in this chapter.) \n",
    "\n",
    "To be more specific, here are the steps that we are going to require, to turn this function into a machine learning classifier:\n",
    "\n",
    "1. *Initialize* the weights.\n",
    "1. For each image, use these weights to *predict* whether it appears to be a 3 or a 7.\n",
    "1. Based on these predictions, calculate how good the model is (its *loss*).\n",
    "1. Calculate the *gradient*, which measures for each weight, how changing that weight would change the loss\n",
    "1. *Step* (that is, change) all the weights based on that calculation.\n",
    "1. Go back to the step 2, and *repeat* the process.\n",
    "1. Iterate until you decide to *stop* the training process (for instance, because the model is good enough or you don't want to wait any longer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17KRQ2O1S-PP"
   },
   "source": [
    "这里我们假设`x`是图像，用一个向量表示——换句话说，所有的行首尾相连地堆叠成一条长线。我们假设权重是一个向量`w`，如果我们有这个函数，那么我们只需要一些方法来更新权重让它们变得更好。通过这种方法，我们可以多次重复该步骤，使权重越来越好，直到它们达到我们所能达到的最好水平。\n",
    "\n",
    "我们想找出向量`w`的具体值，使函数的结果对于那些实际上是8s的图像是高的，对于那些不是8s的图像是低的。寻找最佳向量`w`是搜索识别8的最佳函数的一种方法。(因为我们还没有使用深度神经网络，所以我们受限于我们的函数实际上可以做什么——我们将在本章后面解决这个限制。)\n",
    "\n",
    "更具体地说，以下是我们将需要的步骤，将这个函数变成机器学习分类器:\n",
    "\n",
    "1. *初始化*权重。\n",
    "1. 对于每一张图片，使用这些权重来*预测*它看起来是3还是7。\n",
    "1. 根据这些预测，计算模型的好坏(它的*损失*)。\n",
    "1. 计算*梯度*，测量每个权重，改变权重将如何改变损失\n",
    "1. 根据该计算*逐步*（即更改）所有权重。\n",
    "1. 回到第2步，*重复*这个过程。\n",
    "1. 迭代，直到您决定*停止*训练过程(例如，因为模型已经足够好，或者您不想再等了)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOIZ4ksRsoQt"
   },
   "source": [
    "These seven steps, illustrated in <<gradient_descent>>, are the key to the training of all deep learning models. That deep learning turns out to rely entirely on these steps is extremely surprising and counterintuitive. It's amazing that this process can solve such complex problems. But, as you'll see, it really does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShNIoApcTX2q"
   },
   "source": [
    "这七个步骤，如<<gradient_descent>>所示，是所有深度学习模型训练的关键。事实证明，深度学习完全依赖于这些步骤，这是非常令人惊讶和违反直觉的。令人惊讶的是，这个过程可以解决如此复杂的问题。但是，正如您将看到的，它确实如此!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id gradient_descent\n",
    "#caption The gradient descent process\n",
    "#alt Graph showing the steps for Gradient Descent\n",
    "gv('''\n",
    "init->predict->loss->gradient->step->stop\n",
    "step->predict[label=repeat]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to do each of these seven steps, and we will be learning about them throughout the rest of this book. These are the details that make a big difference for deep learning practitioners, but it turns out that the general approach to each one generally follows some basic principles. Here are a few guidelines:\n",
    "\n",
    "- Initialize:: We initialize the parameters to random values. This may sound surprising. There are certainly other choices we could make, such as initializing them to the percentage of times that pixel is activated for that category—but since we already know that we have a routine to improve these weights, it turns out that just starting with random weights works perfectly well.\n",
    "- Loss:: This is what Samuel referred to when he spoke of *testing the effectiveness of any current weight assignment in terms of actual performance*. We need some function that will return a number that is small if the performance of the model is good (the standard approach is to treat a small loss as good, and a large loss as bad, although this is just a convention).\n",
    "- Step:: A simple way to figure out whether a weight should be increased a bit, or decreased a bit, would be just to try it: increase the weight by a small amount, and see if the loss goes up or down. Once you find the correct direction, you could then change that amount by a bit more, and a bit less, until you find an amount that works well. However, this is slow! As we will see, the magic of calculus allows us to directly figure out in which direction, and by roughly how much, to change each weight, without having to try all these small changes. The way to do this is by calculating *gradients*. This is just a performance optimization, we would get exactly the same results by using the slower manual process as well.\n",
    "- Stop:: Once we've decided how many epochs to train the model for (a few suggestions for this were given in the earlier list), we apply that decision. This is where that decision is applied. For our digit classifier, we would keep training until the accuracy of the model started getting worse, or we ran out of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBnXRrmgUhex"
   },
   "source": [
    "这七个步骤中的每一个都有许多不同的方法，我们将在本书的其余部分学习它们。这些细节对深度学习从业者来说意义重大，但事实证明，处理每个细节的一般方法通常遵循一些基本原则。以下是一些指导方针:\n",
    "\n",
    "- Initialize::我们将参数初始化为随机值。这听起来可能令人惊讶。我们当然可以做出其他选择，例如将它们初始化为该类别的像素被激活的百分比——但是因为我们已经知道我们有一个提高这些权重的例程，事实证明，从随机权重开始工作非常好。\n",
    "- Loss::这就是塞缪尔在谈到*根据实际性能测试当前权重分配的有效性*时所指的。我们需要一些函数，如果模型的性能好，它会返回一个小数字（标准方法是将小损失视为好，将大损失视为坏，尽管这只是一个惯例）。\n",
    "- Step::计算权重是应该增加一点还是减少一点的一个简单方法就是尝试一下:将权重增加一小部分，看看损失是增加还是减少。一旦你找到正确的方向，你可以将这个量再增加一点，或者减少一点，直到你找到一个很好的量。然而，这很慢！正如我们将看到的，微积分的神奇之处让我们可以直接计算出每个权值的变化方向，以及大概变化多少，而不需要尝试所有这些小的变化。做到这一点的方法是计算*梯度*。这只是一个性能优化，通过使用较慢的手动过程，我们也会得到完全相同的结果。\n",
    "- Stop::一旦我们决定了训练模型的 epoch 数(在前面的列表中给出了一些建议)，我们就应用这个决定。这就是应用该决定的地方。对于我们的数字分类器，我们会一直训练，直到模型的准确性开始变差，或者我们的时间用完了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-QepjnesoQv"
   },
   "source": [
    "Before applying these steps to our image classification problem, let's illustrate what they look like in a simpler case. First we will define a very simple function, the quadratic—let's pretend that this is our loss function, and `x` is a weight parameter of the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuUf7hOtU9aa"
   },
   "source": [
    "在将这些步骤应用到我们的图像分类问题之前，让我们用一个更简单的例子来说明它们的样子。首先我们将定义一个非常简单的函数，即二次函数——假设这是我们的损失函数，并且`x`是函数的权重参数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "hCj8JHE_soQv"
   },
   "outputs": [],
   "source": [
    "def f(x): return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oulINLdysoQw"
   },
   "source": [
    "Here is a graph of that function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zkrf3CKVEeZ"
   },
   "source": [
    "这是该函数的图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ztb8z8RmsoQw",
    "outputId": "3a062286-4c3f-46f7-9cf0-facffd1a4ce6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(f, 'x', 'x**2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9FkkmL_soQw"
   },
   "source": [
    "The sequence of steps we described earlier starts by picking some random value for a parameter, and calculating the value of the loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_qbtJHWVJdv"
   },
   "source": [
    "我们前面描述的步骤序列首先为参数选择一些随机值，并计算损失值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "atyDemjIsoQx",
    "outputId": "979de311-b86f-4ebf-a678-84d33367d150"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(f, 'x', 'x**2')\n",
    "plt.scatter(-1.5, f(-1.5), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t891tZyFsoQx"
   },
   "source": [
    "Now we look to see what would happen if we increased or decreased our parameter by a little bit—the *adjustment*. This is simply the slope at a particular point:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTmy4pJVVNpv"
   },
   "source": [
    "现在我们看看如果我们稍微增加或减少参数会发生什么——*调整*。这仅仅是某一点的斜率:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBazyBz0soQy"
   },
   "source": [
    "<img alt=\"A graph showing the squared function with the slope at one point\" width=\"400\" src=\"https://github.com/fastai/fastbook/blob/master/images/grad_illustration.svg?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDIG4EzlsoQy"
   },
   "source": [
    "We can change our weight by a little in the direction of the slope, calculate our loss and adjustment again, and repeat this a few times. Eventually, we will get to the lowest point on our curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25nISLulVSbz"
   },
   "source": [
    "我们可以在斜率方向稍微改变我们的权重，再次计算我们的损失和调整，并重复几次。最终，我们将到达曲线上的最低点:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "550sf1C5soQy"
   },
   "source": [
    "<img alt=\"An illustration of gradient descent\" width=\"400\" src=\"https://github.com/fastai/fastbook/blob/master/images/chapter2_perfect.svg?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da6xBWG6soQz"
   },
   "source": [
    "This basic idea goes all the way back to Isaac Newton, who pointed out that we can optimize arbitrary functions in this way. Regardless of how complicated our functions become, this basic approach of gradient descent will not significantly change. The only minor changes we will see later in this book are some handy ways we can make it faster, by finding better steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsA9Di8YVkf7"
   },
   "source": [
    "这个基本的思想可以追溯到艾萨克·牛顿，他指出我们可以用这种方法优化任意函数。无论我们的函数变得多么复杂，梯度下降的基本方法都不会有明显的变化。我们将在本书后面看到的唯一微小变化是一些方便的方法，可以通过找到更好的步骤来使其更快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cT7uatHsoQz"
   },
   "source": [
    "### Calculating Gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjE7dGq-WBa6"
   },
   "source": [
    "### 计算梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4pST3uPsoQz"
   },
   "source": [
    "The one magic step is the bit where we calculate the gradients. As we mentioned, we use calculus as a performance optimization; it allows us to more quickly calculate whether our loss will go up or down when we adjust our parameters up or down. In other words, the gradients will tell us how much we have to change each weight to make our model better.\n",
    "\n",
    "You may remember from your high school calculus class that the *derivative* of a function tells you how much a change in its parameters will change its result. If not, don't worry, lots of us forget calculus once high school is behind us! But you will have to have some intuitive understanding of what a derivative is before you continue, so if this is all very fuzzy in your head, head over to Khan Academy and complete the [lessons on basic derivatives](https://www.khanacademy.org/math/differential-calculus/dc-diff-intro). You won't have to know how to calculate them yourselves, you just have to know what a derivative is.\n",
    "\n",
    "The key point about a derivative is this: for any function, such as the quadratic function we saw in the previous section, we can calculate its derivative. The derivative is another function. It calculates the change, rather than the value. For instance, the derivative of the quadratic function at the value 3 tells us how rapidly the function changes at the value 3. More specifically, you may recall that gradient is defined as *rise/run*, that is, the change in the value of the function, divided by the change in the value of the parameter. When we know how our function will change, then we know what we need to do to make it smaller. This is the key to machine learning: having a way to change the parameters of a function to make it smaller. Calculus provides us with a computational shortcut, the derivative, which lets us directly calculate the gradients of our functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf2fJ7E8WGry"
   },
   "source": [
    "一个神奇的步骤是我们计算梯度的部分。正如我们提到的，我们使用微积分来进行性能优化；当我们向上或向下调整参数时，它可以让我们更快地计算出我们的损失是增加还是减少。换句话说，梯度将告诉我们，为了使模型更好，我们必须对每个权重改变多少。\n",
    "\n",
    "你可能还记得高中的微积分课上说过，一个函数的*导数*告诉你它的参数的变化会对结果产生多大的影响。如果没有，不要担心，很多人高中毕业后就会忘记微积分！但在你继续之前，你必须对导数有一些直观的理解，所以如果这些在你的脑海中都很模糊，去可汗学院完成[基本导数的课程](https://www.khanacademy.org/math/differential-calculus/dc-diff-intro)。你们不需要知道如何计算它们，你们只需要知道导数是什么。\n",
    "\n",
    "关于导数的关键点是:对于任何函数，比如我们在上一节看到的二次函数，我们都可以计算它的导数。导数是另一个函数。它计算的是变化，而不是值。例如，二次函数在值为3处的导数告诉我们函数在值为3处的变化的速度。更具体地说，你可能还记得梯度被定义为*上升/运行*，即函数值的变化除以参数值的变化。当我们知道函数会如何变化时，我们就知道我们需要做些什么来使它变小。这是机器学习的关键:有一种方法可以改变函数的参数，使其更小。微积分为我们提供了一种计算捷径，即导数，它可以让我们直接计算函数的梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRgFgvw0soQ0"
   },
   "source": [
    "One important thing to be aware of is that our function has lots of weights that we need to adjust, so when we calculate the derivative we won't get back one number, but lots of them—a gradient for every weight. But there is nothing mathematically tricky here; you can calculate the derivative with respect to one weight, and treat all the other ones as constant, then repeat that for each other weight. This is how all of the gradients are calculated, for every weight.\n",
    "\n",
    "We mentioned just now that you won't have to calculate any gradients yourself. How can that be? Amazingly enough, PyTorch is able to automatically compute the derivative of nearly any function! What's more, it does it very fast. Most of the time, it will be at least as fast as any derivative function that you can create by hand. Let's see an example.\n",
    "\n",
    "First, let's pick a tensor value which we want gradients at:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eatH1GSWX0U"
   },
   "source": [
    "需要注意的重要一点是，我们的函数有很多权重需要调整，所以当我们计算导数时，我们不会得到一个数字，而是很多——每个权重的梯度。但这里没有什么数学上的难题；你可以计算一个权重的导数，并将所有其他权重视为常数，然后对其他权重重复此操作。这是计算每个权重的所有梯度的方式。\n",
    "\n",
    "我们刚才提到，你不需要自己计算任何梯度。这怎么可能呢?令人惊讶的是，PyTorch能够自动计算几乎任何函数的导数！更重要的是，它做得非常快。大多数情况下，它至少与您可以手动创建的任何导数函数一样快。我们来看一个例子。\n",
    "\n",
    "首先，让我们选择一个我们想要梯度的张量值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "W-HA32FksoQ0"
   },
   "outputs": [],
   "source": [
    "xt = tensor(3.).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsxLS_txsoQ1"
   },
   "source": [
    "Notice the special method `requires_grad_`? That's the magical incantation we use to tell PyTorch that we want to calculate gradients with respect to that variable at that value. It is essentially tagging the variable, so PyTorch will remember to keep track of how to compute gradients of the other, direct calculations on it that you will ask for.\n",
    "\n",
    "> a: This API might throw you off if you're coming from math or physics. In those contexts the \"gradient\" of a function is just another function (i.e., its derivative), so you might expect gradient-related APIs to give you a new function. But in deep learning, \"gradients\" usually means the _value_ of a function's derivative at a particular argument value. The PyTorch API also puts the focus on the argument, not the function you're actually computing the gradients of. It may feel backwards at first, but it's just a different perspective.\n",
    "\n",
    "Now we calculate our function with that value. Notice how PyTorch prints not just the value calculated, but also a note that it has a gradient function it'll be using to calculate our gradients when needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJvnFERxWdex"
   },
   "source": [
    "注意特殊方法`requires_grad_`?这就是我们用来告诉PyTorch我们想要计算该变量在该值处的梯度的神奇方法。它本质上是标记变量，所以PyTorch会记得跟踪如何计算其他变量的梯度，直接计算你将要求的梯度。\n",
    "\n",
    ">a:如果你是数学或物理出身，这个API可能会让你困惑。在这些情况下，函数的“梯度”只是另一个函数(即它的导数)，所以您可能希望与梯度相关的API提供给您一个新函数。但在深度学习中，“梯度”通常意味着函数在特定参数值处的导数 _值_ 。PyTorch API也将重点放在参数上，而不是实际计算梯度的函数上。一开始可能会觉得有点落后，但这只是一个不同的视角。\n",
    "\n",
    "现在我们使用该值计算我们的函数。请注意PyTorch不仅打印计算的值，还打印了一个注释，说明它有一个梯度函数，它将在需要时用于计算我们的梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ceRnNZdnsoQ1",
    "outputId": "5ec562e6-2f2d-4238-9b1e-c267bdba9790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN2L3QyHsoQ2"
   },
   "source": [
    "Finally, we tell PyTorch to calculate the gradients for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NszzN3J6Wnoe"
   },
   "source": [
    "最后，我们告诉PyTorch为我们计算梯度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "fyXJpCt2soQ2"
   },
   "outputs": [],
   "source": [
    "yt.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKXKyiHKsoQ3"
   },
   "source": [
    "The \"backward\" here refers to *backpropagation*, which is the name given to the process of calculating the derivative of each layer. We'll see how this is done exactly in chapter <<chapter_foundations>>, when we calculate the gradients of a deep neural net from scratch. This is called the \"backward pass\" of the network, as opposed to the \"forward pass,\" which is where the activations are calculated. Life would probably be easier if `backward` was just called `calculate_grad`, but deep learning folks really do like to add jargon everywhere they can!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfRV1pMJWrcc"
   },
   "source": [
    "这里的“向后”指的是*反向传播*，即计算每一层导数的过程。当我们从头开始计算深度神经网络的梯度时，我们将在<<chapter_foundations>>章中看到这是如何准确地完成的，这被称为网络的“向后传递”，而不是“向前传递”，后者是计算激活的地方。如果`backward`只被称为`calculate_grad`，可能更容易理解，但深度学习的人真的喜欢在任何地方添加术语！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAAohGzZsoQ3"
   },
   "source": [
    "We can now view the gradients by checking the `grad` attribute of our tensor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Yltj3hrXAFK"
   },
   "source": [
    "现在我们可以通过检查我们张量的`grad`属性来查看梯度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "mBH7mcZksoQ3",
    "outputId": "bfdc1f32-50aa-475d-bd6b-fc5464ca69ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1xhp_rosoQ4"
   },
   "source": [
    "If you remember your high school calculus rules, the derivative of `x**2` is `2*x`, and we have `x=3`, so the gradients should be `2*3=6`, which is what PyTorch calculated for us!\n",
    "\n",
    "Now we'll repeat the preceding steps, but with a vector argument for our function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ7ABXAFXGZm"
   },
   "source": [
    "如果你还记得高中的微积分规则，`x**2`的导数是`2*x`，我们有`x=3`，所以梯度应该是`2*3=6`，这是PyTorch为我们计算的!\n",
    "\n",
    "现在，我们将重复前面的步骤，但对我们的函数使用向量参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "GcvwXcxasoQ6",
    "outputId": "b177c253-4a1f-4362-f5b4-0a086c4caf51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  4., 10.], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = tensor([3.,4.,10.]).requires_grad_()\n",
    "xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "351SiF7PsoQ6"
   },
   "source": [
    "And we'll add `sum` to our function so it can take a vector (i.e., a rank-1 tensor), and return a scalar (i.e., a rank-0 tensor):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6tpbOyaXWyQ"
   },
   "source": [
    "我们将`sum`添加到我们的函数中，以便它可以接受一个向量(即一个秩1张量)，并返回一个标量(即一个秩0张量):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "CW94lTvJsoQ7",
    "outputId": "d6d82bbf-206f-43de-c8bc-fcff4b59966e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return (x**2).sum()\n",
    "\n",
    "yt = f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJQzpX12soQ7"
   },
   "source": [
    "Our gradients are `2*xt`, as we'd expect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXzweHqCXfSH"
   },
   "source": [
    "我们的梯度是`2*xt`，正如我们所期望的那样!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "h3Fb4VLhsoQ7",
    "outputId": "ead2dcaf-1e54-41fd-e3f7-bc78a8a8a83f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 20.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nqd-89AsoQ8"
   },
   "source": [
    "The gradients only tell us the slope of our function, they don't actually tell us exactly how far to adjust the parameters. But it gives us some idea of how far; if the slope is very large, then that may suggest that we have more adjustments to do, whereas if the slope is very small, that may suggest that we are close to the optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT79obI_xeE2"
   },
   "source": [
    "梯度只告诉我们函数的斜率，它们实际上并没有告诉我们参数要调整到什么程度。但它让我们知道了有多远；如果斜率很大，那可能意味着我们需要做更多的调整，而如果斜率很小，那可能意味着我们接近最优值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_1t3G9MsoQ8"
   },
   "source": [
    "### Stepping With a Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTZjbD1Mxkox"
   },
   "source": [
    "### 以学习率步进"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC2f9HNcsoQ8"
   },
   "source": [
    "Deciding how to change our parameters based on the values of the gradients is an important part of the deep learning process. Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the *learning rate* (LR). The learning rate is often a number between 0.001 and 0.1, although it could be anything. Often, people select a learning rate just by trying a few, and finding which results in the best model after training (we'll show you a better approach later in this book, called the *learning rate finder*). Once you've picked a learning rate, you can adjust your parameters using this simple function:\n",
    "\n",
    "```\n",
    "w -= gradient(w) * lr\n",
    "```\n",
    "\n",
    "This is known as *stepping* your parameters, using an *optimizer step*. Notice how we _subtract_ the `gradient * lr` from the parameter to update it.  This allows us to adjust the parameter in the direction of the slope by increasing the parameter when the slope is negative and decreasing the parameter when the slope is positive.  We want to adjust our parameters in the direction of the slope because our goal in deep learning is to _minimize_ the loss.\n",
    "\n",
    "If you pick a learning rate that's too low, it can mean having to do a lot of steps. <<descent_small>> illustrates that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_o6zbY5xpm3"
   },
   "source": [
    "决定如何根据梯度的值改变我们的参数是深度学习过程的重要组成部分。几乎所有的方法都是从将梯度乘以一个小的数字的基本思想开始的，称为*学习率*(LR)。学习率通常是0.001到0.1之间的一个数字，尽管它可以是任何值。通常，人们只需尝试几个，并在训练后找到最佳模型(我们将在本书后面介绍一种更好的方法，称为*学习率查找器*)即可选择学习率。一旦你选择了一个学习率，你就可以使用这个简单的函数来调整你的参数:\n",
    "\n",
    "```\n",
    "w -= gradient(w) * lr\n",
    "```\n",
    "\n",
    "这称为*步进*参数，使用*优化器步骤*。注意我们如何从参数中减去`gradient * lr`来更新它。这允许我们通过在斜率为负时增加参数并在斜率为正时减少参数来调整斜率方向的参数。我们想要在斜率的方向上调整我们的参数，因为我们在深度学习中的目标是 _最小化_ 损失。\n",
    "\n",
    "如果你选择的学习率太低，则可能意味着必须执行很多步骤。<<descent_small>>说明了这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvmTTDHhsoQ9"
   },
   "source": [
    "<img alt=\"An illustration of gradient descent with a LR too low\" width=\"400\" caption=\"Gradient descent with low LR\" src=\"https://github.com/fastai/fastbook/blob/master/images/chapter2_small.svg?raw=1\" id=\"descent_small\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rKOCrsrsoQ9"
   },
   "source": [
    "But picking a learning rate that's too high is even worse—it can actually result in the loss getting *worse*, as we see in <<descent_div>>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rsBmXbGx8Vy"
   },
   "source": [
    "但是选择一个太高的学习率会更糟——它实际上会导致损失变得*更糟*，正如我们在<<descent_div>>中看到的那样！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl9EAN7nsoQ9"
   },
   "source": [
    "<img alt=\"An illustration of gradient descent with a LR too high\" width=\"400\" caption=\"Gradient descent with high LR\" src=\"https://github.com/fastai/fastbook/blob/master/images/chapter2_div.svg?raw=1\" id=\"descent_div\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UcsHpmFsoQ-"
   },
   "source": [
    "If the learning rate is too high, it may also \"bounce\" around, rather than actually diverging; <<descent_bouncy>> shows how this has the result of taking many steps to train successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YZJuhB4yHKL"
   },
   "source": [
    "如果学习率太高，它也可能“反弹”，而不是实际发散；<<descent_bouncy>>显示了这是如何采取许多步骤来成功训练的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYm1AW35soQ-"
   },
   "source": [
    "<img alt=\"An illustation of gradient descent with a bouncy LR\" width=\"400\" caption=\"Gradient descent with bouncy LR\" src=\"https://github.com/fastai/fastbook/blob/master/images/chapter2_bouncy.svg?raw=1\" id=\"descent_bouncy\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0PNGm0jsoQ_"
   },
   "source": [
    "Now let's apply all of this in an end-to-end example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbErMu5bySgo"
   },
   "source": [
    "现在让我们在一个端到端的例子中应用所有这些。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDnLhyVJsoRA"
   },
   "source": [
    "### An End-to-End SGD Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzZ4BUBUyXWT"
   },
   "source": [
    "### 端到端SGD示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a67yxWP1soRB"
   },
   "source": [
    "We've seen how to use gradients to find a minimum. Now it's time to look at an SGD example and see how finding a minimum can be used to train a model to fit data better.\n",
    "\n",
    "Let's start with a simple, synthetic, example model. Imagine you were measuring the speed of a roller coaster as it went over the top of a hump. It would start fast, and then get slower as it went up the hill; it would be slowest at the top, and it would then speed up again as it went downhill. You want to build a model of how the speed changes over time. If you were measuring the speed manually every second for 20 seconds, it might look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZnPPowmycF7"
   },
   "source": [
    "我们已经学习了如何使用梯度来来找到最小值。现在我们来看一个SGD示例，看看如何使用找到的最小值来训练模型以更好地拟合数据。\n",
    "\n",
    "让我们从一个简单的、合成的示例模型开始。假设你正在测量过山车在越过驼峰顶部时的速度。它会快速开始，然后在上坡时变慢；它在顶部最慢，然后在下坡时再次加速。你想建立一个速度随时间变化的模型。如果你每秒手动测量一次速度，持续20秒，它可能看起来像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "fstFPcsksoRC",
    "outputId": "753594e0-307f-420a-8728-ea5e72edc121"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "H0lepBjbsoRC",
    "outputId": "dc834a3e-13ea-48a9-d453-28764e0783ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(time,speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LDJrTezsoRD"
   },
   "source": [
    "We've added a bit of random noise, since measuring things manually isn't precise. This means it's not that easy to answer the question: what was the roller coaster's speed? Using SGD we can try to find a function that matches our observations. We can't consider every possible function, so let's use a guess that it will be quadratic; i.e., a function of the form `a*(time**2)+(b*time)+c`.\n",
    "\n",
    "We want to distinguish clearly between the function's input (the time when we are measuring the coaster's speed) and its parameters (the values that define *which* quadratic we're trying). So, let's collect the parameters in one argument and thus separate the input, `t`, and the parameters, `params`, in the function's signature: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr1APys3yhLa"
   },
   "source": [
    "我们添加了一些随机噪声，因为手动测量并不精确。这意味着要回答这个问题并不容易：过山车的速度是多少?使用SGD，我们可以尝试找到一个与我们的观察结果相匹配的函数。我们不能考虑所有可能的函数，所以我们假设它是二次函数;即:`a*(time**2)+(b*time)+c`形式的函数。\n",
    "\n",
    "我们想要清楚地区分函数的输入(我们测量过山车速度的时间)和它的参数(定义我们尝试*的*二次函数的值)。因此，让我们在一个参数中收集参数，从而在函数签名中将输入`t`和参数`params`分开:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "O7jIYHewsoRD"
   },
   "outputs": [],
   "source": [
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX0hfqbQsoRE"
   },
   "source": [
    "In other words, we've restricted the problem of finding the best imaginable function that fits the data, to finding the best *quadratic* function. This greatly simplifies the problem, since every quadratic function is fully defined by the three parameters `a`, `b`, and `c`. Thus, to find the best quadratic function, we only need to find the best values for `a`, `b`, and `c`.\n",
    "\n",
    "If we can solve this problem for the three parameters of a quadratic function, we'll be able to apply the same approach for other, more complex functions with more parameters—such as a neural net. Let's find the parameters for `f` first, and then we'll come back and do the same thing for the MNIST dataset with a neural net.\n",
    "\n",
    "We need to define first what we mean by \"best.\" We define this precisely by choosing a *loss function*, which will return a value based on a prediction and a target, where lower values of the function correspond to \"better\" predictions. It is important for loss functions to return _lower_ values when predictions are more accurate, as the SGD procedure we defined earlier will try to _minimize_ this loss. For continuous data, it's common to use *mean squared error*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiMZepqNyuW6"
   },
   "source": [
    "换句话说，我们将寻找适合数据的最佳可想象函数的问题限制为寻找最佳*二次*函数。这大大简化了问题，因为每个二次函数都完全由三个参数`a`, `b`，和`c`定义。因此，要找到最佳二次函数，我们只需要找到`a`, `b`，和`c`的最佳值。\n",
    "\n",
    "如果我们能解决二次函数的三个参数的问题，我们就能将同样的方法应用于其他更复杂的、参数更多的函数——比如神经网络。让我们先找到`f`的参数，然后我们回来用神经网络对MNIST数据集做同样的事情。\n",
    "\n",
    "我们首先需要定义“最佳”的含义。我们通过选择一个*损失函数*来精确地定义这一点，该损失函数将根据预测和目标返回一个值，其中函数的较低值对应“更好”的预测。当预测更准确时，损失函数返回较低的值是很重要的，因为我们之前定义的SGD过程将尝试 _最小化_ 这种损失。对于连续数据，通常使用*均方误差*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "R79ypqw4soRE"
   },
   "outputs": [],
   "source": [
    "def mse(preds, targets): return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaYqrIshsoRE"
   },
   "source": [
    "Now, let's work through our 7 step process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_HQkRyGzP6m"
   },
   "source": [
    "现在，让我们来完成我们的7个步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYeTeKJHsoRF"
   },
   "source": [
    "#### Step 1: Initialize the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWWyKJzuzUc6"
   },
   "source": [
    "#### 第1步:初始化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAlgJk2asoRF"
   },
   "source": [
    "First, we initialize the parameters to random values, and tell PyTorch that we want to track their gradients, using `requires_grad_`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSvY64GbzbWP"
   },
   "source": [
    "首先，我们将参数初始化为随机值，并告诉PyTorch我们想使用`requires_grad_`跟踪它们的梯度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "vh9WX3wosoRG"
   },
   "outputs": [],
   "source": [
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "c-VhU9EZsoRH"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "orig_params = params.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRh7gsMDsoRH"
   },
   "source": [
    "#### Step 2: Calculate the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr5AfJuszjAH"
   },
   "source": [
    "#### 第2步:计算预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF21e6A3soRH"
   },
   "source": [
    "Next, we calculate the predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-ujqiXfzp9l"
   },
   "source": [
    "接下来，我们计算预测:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "TYff6RxcsoRH"
   },
   "outputs": [],
   "source": [
    "preds = f(time, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQx-Wz7SsoRI"
   },
   "source": [
    "Let's create a little function to see how close our predictions are to our targets, and take a look:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC-O3xAezuT1"
   },
   "source": [
    "让我们创建一个小函数来看看我们的预测与我们的目标有多接近，然后看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Iz4O7nHrsoRI"
   },
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "h6GkO-nWsoRI",
    "outputId": "7bccf453-e953-4d05-f62c-25eca5770550"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_DgnF32soRJ"
   },
   "source": [
    "This doesn't look very close—our random parameters suggest that the roller coaster will end up going backwards, since we have negative speeds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl5HGVvUz1Sw"
   },
   "source": [
    "这看起来不是很接近——我们的随机参数表明过山车最终会倒退，因为我们有负速度！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ik2o6IwTsoRJ"
   },
   "source": [
    "#### Step 3: Calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHmxXM05z6J-"
   },
   "source": [
    "#### 第3步:计算损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWTi9FLmsoRK"
   },
   "source": [
    "We calculate the loss as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apWujY7c0FY4"
   },
   "source": [
    "我们计算损失如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "BpUPEfCDsoRK",
    "outputId": "bbd904f2-94a2-463a-aa9d-a3eb1edfa5fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25823.8086, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(preds, speed)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qXy3vx8soRK"
   },
   "source": [
    "Our goal is now to improve this. To do that, we'll need to know the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGobeVv70Kd6"
   },
   "source": [
    "我们现在的目标是改进这一点。要做到这一点，我们需要知道梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaC7k_R0soRK"
   },
   "source": [
    "#### Step 4: Calculate the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6Cv8sha0PcF"
   },
   "source": [
    "#### 第4步:计算梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVpV2dwasoRL"
   },
   "source": [
    "The next step is to calculate the gradients. In other words, calculate an approximation of how the parameters need to change:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ganZ8XOD0WzH"
   },
   "source": [
    "下一步是计算梯度。换句话说，计算参数需要如何变化的近似值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "OTiq4DVlsoRL",
    "outputId": "a2127d61-4af4-4aed-c127-0366ddb6a06f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-53195.8633,  -3419.7148,   -253.8908])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "crIEHkotsoRL",
    "outputId": "f9043bca-fc21-45fe-d56b-ed5997c206b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5320, -0.0342, -0.0025])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fn03AZrgsoRM"
   },
   "source": [
    "We can use these gradients to improve our parameters. We'll need to pick a learning rate (we'll discuss how to do that in practice in the next chapter; for now we'll just use 1e-5, or 0.00001):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-rbj9WZ0btI"
   },
   "source": [
    "我们可以使用这些梯度来改进我们的参数。我们需要选择一个学习率(我们将在下一章讨论如何在实践中做到这一点；现在我们只使用1e-5，或0.00001):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "zYeSveOzsoRM",
    "outputId": "bb7ec315-e1d2-4efc-c737-c6284e62c5c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7658, -0.7506,  1.3525], requires_grad=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc0e0ZIQsoRM"
   },
   "source": [
    "#### Step 5: Step the weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHDLSo0B0kdz"
   },
   "source": [
    "#### 第5步:步进权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5w0Mi16soRN"
   },
   "source": [
    "Now we need to update the parameters based on the gradients we just calculated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPt4wY342JoI"
   },
   "source": [
    "现在我们需要基于我们刚刚计算的梯度更新参数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "q_xXf6J_soRN"
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL1SiA67soRN"
   },
   "source": [
    "> a: Understanding this bit depends on remembering recent history. To calculate the gradients we call `backward` on the `loss`. But this `loss` was itself calculated by `mse`, which in turn took `preds` as an input, which was calculated using `f` taking as an input `params`, which was the object on which we originally called `requires_grad_`—which is the original call that now allows us to call `backward` on `loss`. This chain of function calls represents the mathematical composition of functions, which enables PyTorch to use calculus's chain rule under the hood to calculate these gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e40SHsRr2PJH"
   },
   "source": [
    ">a:理解这一点取决于记住最近的历史。为了计算梯度，我们在`loss`上调用`backward`。但是这个`loss`本身是由`mse`计算的，它反过来以`preds`作为输入，使用`f`作为输入`params`进行计算，这是我们最初调用`requires_grad_`的对象——这是现在允许我们在`loss`上调用`backward`的原始调用。这个函数调用链表示函数的数学组成，这使得PyTorch能够在底层使用微积分的链式法则来计算这些梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eyU4YomsoRN"
   },
   "source": [
    "Let's see if the loss has improved:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ8QViik2U2c"
   },
   "source": [
    "让我们看看损失是否有所改善:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "bDUF4aSbsoRO",
    "outputId": "0355152a-7c1a-4fb6-986e-48dc4c5dadf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5435.5356, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = f(time,params)\n",
    "mse(preds, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyWusxpHsoRP"
   },
   "source": [
    "And take a look at the plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jowwkIaq2ZV7"
   },
   "source": [
    "我们来看一下图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "J8isFZeEsoRP",
    "outputId": "99200247-b632-484a-eaeb-664bf1bf05d4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHKmfkwfsoRQ"
   },
   "source": [
    "We need to repeat this a few times, so we'll create a function to apply one step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzsJJBe82n-u"
   },
   "source": [
    "我们需要重复几次，所以我们将创建一个函数来应用一步:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "YmVtIBCTsoRQ"
   },
   "outputs": [],
   "source": [
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HUkwM3PsoRQ"
   },
   "source": [
    "#### Step 6: Repeat the process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0VIIfCO3JGe"
   },
   "source": [
    "#### 第6步:重复该过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIl8WVkgsoRQ"
   },
   "source": [
    "Now we iterate. By looping and performing many improvements, we hope to reach a good result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SH1e5883P4V"
   },
   "source": [
    "现在我们进行迭代。通过循环和执行许多改进，我们希望得到一个好的结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "FX8Ym_oHsoRR",
    "outputId": "e8d0831f-f951-4ac2-827f-872fa5597d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435.53564453125\n",
      "1577.44921875\n",
      "847.3778076171875\n",
      "709.2225341796875\n",
      "683.0758056640625\n",
      "678.1243896484375\n",
      "677.1838989257812\n",
      "677.0023193359375\n",
      "676.9645385742188\n",
      "676.9537353515625\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "shlWgfpmsoRR"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "params = orig_params.detach().requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7raAX8qsoRR"
   },
   "source": [
    "The loss is going down, just as we hoped! But looking only at these loss numbers disguises the fact that each iteration represents an entirely different quadratic function being tried, on the way to finding the best possible quadratic function. We can see this process visually if, instead of printing out the loss function, we plot the function at every step. Then we can see how the shape is approaching the best possible quadratic function for our data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbyMdSec3WgF"
   },
   "source": [
    "损失正在下降，正如我们所希望的那样！但只看这些损失数字掩盖了这样一个事实:即每次迭代都代表一个完全不同的二次函数，正在尝试寻找最好的二次函数。如果不是打印损失函数，而是在每一步绘制函数，我们就可以直观地看到这个过程。然后我们可以看到形状如何接近我们数据的最佳二次函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "A4veBhJasoRS",
    "outputId": "e8ebc9f0-0871-44f5-f94e-f56e36422e14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44l8D4YVsoRS"
   },
   "source": [
    "#### Step 7: stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKj6Rd3j3bzl"
   },
   "source": [
    "#### 第7步:停止"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcOtbmN7soRT"
   },
   "source": [
    "We just decided to stop after 10 epochs arbitrarily. In practice, we would watch the training and validation losses and our metrics to decide when to stop, as we've discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0GiVGEw3h7R"
   },
   "source": [
    "我们只是随意决定在10轮后停止。在实践中，我们会观察训练和验证损失以及我们的指标来决定何时停止，正如我们所讨论的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU2IOFIZsoRT"
   },
   "source": [
    "### Summarizing Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UuB-tJI3pOF"
   },
   "source": [
    "### 总结梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "id": "Q-TLoqeJsoRT",
    "outputId": "56591053-e001-49b9-e2cf-6b5ff95f0caa"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"591pt\" height=\"78pt\"\n",
       " viewBox=\"0.00 0.00 591.49 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 587.4867,-74 587.4867,4 -4,4\"/>\n",
       "<!-- init -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>init</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n",
       "</g>\n",
       "<!-- predict -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>predict</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"126.0969\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.0969\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n",
       "</g>\n",
       "<!-- init&#45;&gt;predict -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>init&#45;&gt;predict</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.0787,-18C62.3227,-18 71.6196,-18 80.7269,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.8626,-21.5001 90.8626,-18 80.8625,-14.5001 80.8626,-21.5001\"/>\n",
       "</g>\n",
       "<!-- loss -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>loss</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"225.1938\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.1938\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n",
       "</g>\n",
       "<!-- predict&#45;&gt;loss -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>predict&#45;&gt;loss</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M155.2932,-28.0172C166.6224,-31.9043 179.6698,-36.3808 191.4018,-40.406\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.2859,-43.7234 200.8806,-43.6582 192.5577,-37.1023 190.2859,-43.7234\"/>\n",
       "</g>\n",
       "<!-- gradient -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>gradient</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"361.8403\" cy=\"-52\" rx=\"39.7935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.8403\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n",
       "</g>\n",
       "<!-- loss&#45;&gt;gradient -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>loss&#45;&gt;gradient</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252.5178,-52C269.4967,-52 291.836,-52 311.8929,-52\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.1329,-55.5001 322.1329,-52 312.1328,-48.5001 312.1329,-55.5001\"/>\n",
       "</g>\n",
       "<!-- step -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>step</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"465.4867\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"465.4867\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n",
       "</g>\n",
       "<!-- gradient&#45;&gt;step -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>gradient&#45;&gt;step</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M394.0665,-41.4286C405.9515,-37.5298 419.4492,-33.1021 431.4862,-29.1535\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"432.7754,-32.4142 441.1862,-25.9715 430.5935,-25.7629 432.7754,-32.4142\"/>\n",
       "</g>\n",
       "<!-- step&#45;&gt;predict -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>step&#45;&gt;predict</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M438.4132,-18C380.3272,-18 243.2155,-18 171.5401,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.4571,-14.5001 161.4571,-18 171.4571,-21.5001 171.4571,-14.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.1938\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n",
       "</g>\n",
       "<!-- stop -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>stop</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"556.4867\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"556.4867\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n",
       "</g>\n",
       "<!-- step&#45;&gt;stop -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>step&#45;&gt;stop</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M492.7897,-18C501.068,-18 510.3085,-18 519.1272,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"519.203,-21.5001 529.203,-18 519.203,-14.5001 519.203,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f10d352e250>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#id gradient_descent\n",
    "#caption The gradient descent process\n",
    "#alt Graph showing the steps for Gradient Descent\n",
    "gv('''\n",
    "init->predict->loss->gradient->step->stop\n",
    "step->predict[label=repeat]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59bQAgrBsoRU"
   },
   "source": [
    "To summarize, at the beginning, the weights of our model can be random (training *from scratch*) or come from a pretrained model (*transfer learning*). In the first case, the output we will get from our inputs won't have anything to do with what we want, and even in the second case, it's very likely the pretrained model won't be very good at the specific task we are targeting. So the model will need to *learn* better weights.\n",
    "\n",
    "We begin by comparing the outputs the model gives us with our targets (we have labeled data, so we know what result the model should give) using a *loss function*, which returns a number that we want to make as low as possible by improving our weights. To do this, we take a few data items (such as images) from the training set and feed them to our model. We compare the corresponding targets using our loss function, and the score we get tells us how wrong our predictions were. We then change the weights a little bit to make it slightly better.\n",
    "\n",
    "To find how to change the weights to make the loss a bit better, we use calculus to calculate the *gradients*. (Actually, we let PyTorch do it for us!) Let's consider an analogy. Imagine you are lost in the mountains with your car parked at the lowest point. To find your way back to it, you might wander in a random direction, but that probably wouldn't help much. Since you know your vehicle is at the lowest point, you would be better off going downhill. By always taking a step in the direction of the steepest downward slope, you should eventually arrive at your destination. We use the magnitude of the gradient (i.e., the steepness of the slope) to tell us how big a step to take; specifically, we multiply the gradient by a number we choose called the *learning rate* to decide on the step size. We then *iterate* until we have reached the lowest point, which will be our parking lot, then we can *stop*.\n",
    "\n",
    "All of that we just saw can be transposed directly to the MNIST dataset, except for the loss function. Let's now see how we can define a good training objective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34tldJQU377G"
   },
   "source": [
    "总而言之，在一开始，我们模型的权重可以是随机的(*从头开始*训练)，也可以来自一个预训练模型(*迁移学习*)。在第一种情况下，我们从输入中得到的输出与我们想要的没有任何关系，即使在第二种情况下，预训练的模型也很可能不能很好地完成我们的目标任务。因此，模型需要*学习*更好的权重。\n",
    "\n",
    "首先，我们使用一个*损失函数*将模型给出的输出与目标(我们已经标记了数据，因此我们知道模型应该给出什么结果)进行比较，它返回一个我们希望通过改进权重使其尽可能低的数字。为此，我们从训练集中获取一些数据项(如图像)，并将它们提供给我们的模型。我们使用我们的损失函数来比较相应的目标，我们得到的分数告诉我们我们的预测有多错误。然后我们稍微改变一下权重，让它稍微好一点。\n",
    "\n",
    "为了找到如何改变权重使损失更好一点，我们使用微积分来计算*梯度*。(实际上，我们让PyTorch为我们做这件事！)让我们打个比方。想象一下，你在山里迷路了，车停在最低的地方。为了找到回到车的路，你可能会在一个随机的方向徘徊，但这可能没有多大帮助。因为你知道你的车在最低点，你最好下坡。通过始终朝着最陡峭的下坡方向迈出一步，你最终应该到达目的地。我们使用梯度的大小(即坡度的陡度)来告诉我们要迈出多大的步幅；具体来说，我们将梯度乘以我们选择的称为*学习率*的数字来决定步长。然后*迭代*，直到到达最低点，也就是我们的停车场，然后我们就可以*停止*了。\n",
    "\n",
    "除了损失函数之外，我们刚刚看到的所有内容都可以直接转置到MNIST数据集。现在让我们看看如何定义一个好的训练目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnTveWjYsoRU"
   },
   "source": [
    "## The MNIST Loss Function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnCKa_Yi4Hl_"
   },
   "source": [
    "## MNIST损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb3iofvZsoRV"
   },
   "source": [
    "We already have our independent variables `x`—these are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using `view`, which is a PyTorch method that changes the shape of a tensor without changing its contents. `-1` is a special parameter to `view` that means \"make this axis as big as necessary to fit all the data\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx8Q8w-P4PXp"
   },
   "source": [
    "我们已经有了自变量`x`——这些是图像本身。我们将把它们全部连接成一个张量，并将它们从矩阵列表(秩为3的张量)变成向量列表(秩为2的张量)。我们可以使用`view`来实现这一点，它是一个PyTorch方法，可以改变张量的形状，而不改变其内容。`-1`是`view`的一个特殊参数，它意味着“使这个轴尽可能大，以适应所有数据”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ZrO-K8APsoRV"
   },
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn9Xlnr3soRW"
   },
   "source": [
    "We need a label for each image. We'll use `1` for 3s and `0` for 7s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGBO1uu24zrX"
   },
   "source": [
    "我们需要为每个图像添加一个标签。我们用`1`表示3s, `0`表示7s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "WwszSIb0soRX",
    "outputId": "c9109815-1e96-41fd-c255-0ce1af8223a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnNrE9BWsoRY"
   },
   "source": [
    "A `Dataset` in PyTorch is required to return a tuple of `(x,y)` when indexed. Python provides a `zip` function which, when combined with `list`, provides a simple way to get this functionality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FrW5QoG9O_q"
   },
   "source": [
    "PyTorch中的`Dataset`需要在索引时返回`(x,y)`的元组。Python提供了一个`zip`函数，当与`list`结合使用时，它提供了一种简单的方法来获得此功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "wSuzmMCwsoRY",
    "outputId": "a9b7c2a8-51cf-405d-f3a5-1221cc054baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "LyPvXUuWsoRZ"
   },
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVd6YgfosoRZ"
   },
   "source": [
    "Now we need an (initially random) weight for every pixel (this is the *initialize* step in our seven-step process):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHXr-1aC9YB2"
   },
   "source": [
    "现在我们需要每个像素的一个(最初是随机的)权重(这是我们的七步过程中的初始化步骤):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "AMPS6T7ksoRZ"
   },
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "M4x3Z8YMsoRa"
   },
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxGkLlw7soRa"
   },
   "source": [
    "The function `weights*pixels` won't be flexible enough—it is always equal to 0 when the pixels are equal to 0 (i.e., its *intercept* is 0). You might remember from high school math that the formula for a line is `y=w*x+b`; we still need the `b`. We'll initialize it to a random number too:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPunvDjM9cIR"
   },
   "source": [
    "函数`weights*pixels`不够灵活——当像素等于0时，它总是等于0(即，它的*截距*为0)。你可能还记得高中数学中的直线公式是`y=w*x+b`;我们仍然需要`b`。我们也将其初始化为一个随机数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "FruKbeRCsoRa"
   },
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-9f7CZfsoRa"
   },
   "source": [
    "In neural networks, the `w` in the equation `y=w*x+b` is called the *weights*, and the `b` is called the *bias*. Together, the weights and bias make up the *parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HgqPJrW9jbO"
   },
   "source": [
    "在神经网络中，方程`y=w*x+b`中的`w`称为*权重*，`b`称为*偏差*。权重和偏差共同构成了*参数*。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVLOqVDOsoRb"
   },
   "source": [
    "> jargon: Parameters: The _weights_ and _biases_ of a model. The weights are the `w` in the equation `w*x+b`, and the biases are the `b` in that equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DMXucS9qso"
   },
   "source": [
    ">术语：参数:模型的 _权重_ 和 _偏差_ 。权重是方程`w*x+b`中的`w`，偏差是方程中的`b`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pOXIAxqsoRb"
   },
   "source": [
    "We can now calculate a prediction for one image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iqEldNW9xE7"
   },
   "source": [
    "我们现在可以计算一个图像的预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "XdI-ZLYvsoRb",
    "outputId": "7e9bdf8d-c253-4d52-a917-9ace84c3404c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.2336], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMQA2j5bsoRb"
   },
   "source": [
    "While we could use a Python `for` loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n",
    "\n",
    "In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix—it's called *matrix multiplication*. <<matmul>> shows what matrix multiplication looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDVHqE-h91K9"
   },
   "source": [
    "虽然我们可以使用Python `for`循环来计算每个图像的预测，但这会非常慢。因为Python循环不在GPU上运行，而且Python通常对于循环来说是一种慢速语言，所以我们需要使用更高级的函数在模型中表示尽可能多的计算。\n",
    "\n",
    "在这种情况下，有一个非常方便的数学运算可以计算`w*x`矩阵的每一行——它被称为矩阵乘法。<<matmul>>显示了矩阵乘法的样子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP6r2W3XsoRc"
   },
   "source": [
    "<img alt=\"Matrix multiplication\" width=\"400\" caption=\"Matrix multiplication\" src=\"https://github.com/fastai/fastbook/blob/master/images/matmul2.svg?raw=1\" id=\"matmul\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFgeEUSbsoRc"
   },
   "source": [
    "This image shows two matrices, `A` and `B`, being multiplied together. Each item of the result, which we'll call `AB`, contains each item of its corresponding row of `A` multiplied by each item of its corresponding column of `B`, added together. For instance, row 1, column 2 (the yellow dot with a red border) is calculated as $a_{1,1} * b_{1,2} + a_{1,2} * b_{2,2}$. If you need a refresher on matrix multiplication, we suggest you take a look at the [Intro to Matrix Multiplication](https://youtu.be/kT4Mp9EdVqs) on *Khan Academy*, since this is the most important mathematical operation in deep learning.\n",
    "\n",
    "In Python, matrix multiplication is represented with the `@` operator. Let's try it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-THDktCCwF0"
   },
   "source": [
    "这幅图显示了两个矩阵`A`和`B`相乘。结果中的每一项，我们称之为`AB`，包含对应的`A`行中的每一项乘以对应的`B`列中的每一项，相加。例如，第1行第2列(红色边框的黄色圆点)被计算为$a_{1,1} * b_{1,2} + a_{1,2} * b_{2,2}$。如果你需要复习矩阵乘法，我们建议你看看*可汗学院*的[矩阵乘法简介](https://youtu.be/kT4Mp9EdVqs)，因为这是深度学习中最重要的数学运算。\n",
    "\n",
    "在Python中，矩阵乘法用`@`运算符表示。让我们尝试一下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "0FrKqEuesoRc",
    "outputId": "4c970065-2871-4ade-e376-32a6a063fa32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.2336],\n",
       "        [17.0644],\n",
       "        [15.2384],\n",
       "        ...,\n",
       "        [18.3804],\n",
       "        [23.8567],\n",
       "        [28.6816]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4qVAuOJsoRd"
   },
   "source": [
    "The first element is the same as we calculated before, as we'd expect. This equation, `batch@weights + bias`, is one of the two fundamental equations of any neural network (the other one is the *activation function*, which we'll see in a moment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7_fb61KDIiJ"
   },
   "source": [
    "正如我们所料，第一个元素和我们之前计算的相同。这个方程`batch@weights + bias`是任何神经网络的两个基本方程之一(另一个是*激活函数*，我们稍后会看到)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUX_IAz5soRd"
   },
   "source": [
    "Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, so our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI4F3UzvDREI"
   },
   "source": [
    "让我们检查一下我们的准确性。要确定输出是代表3还是7，我们只需检查它是否大于0.0，因此可以计算每个项目的准确度(使用广播，所以没有循环!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "wI4xyJLPsoRd",
    "outputId": "f73b4d34-d31f-494b-8abf-17cc4961fa0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "viKrPjmJsoRe",
    "outputId": "b82216cd-5c80-4b30-c6a8-0e1664995235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912068545818329"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtNCksyHsoRf"
   },
   "source": [
    "Now let's see what the change in accuracy is for a small change in one of the weights (note that we have to ask PyTorch not to calculate gradients as we do this, which is what `with torch.no_grad()` is doing here):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnji1HpUERPh"
   },
   "source": [
    "现在让我们看看对于其中一个权重的微小变化，准确度的变化是什么(请注意，我们必须要求 PyTorch 在我们这样做时不要计算梯度，这就是`with torch.no_grad()`这里所做的):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "cG0S5aZ2soRf"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "n3pXhnNosoRf",
    "outputId": "59950a7f-0d83-4bfc-d164-c2485fcaa530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912068545818329"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kh-MiOCrsoRg"
   },
   "source": [
    "As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some *loss function* that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.\n",
    "\n",
    "So, we need to choose a loss function. The obvious approach would be to use accuracy, which is our metric, as our loss function as well. In this case, we would calculate our prediction for each image, collect these values to calculate an overall accuracy, and then calculate the gradients of each weight with respect to that overall accuracy.\n",
    "\n",
    "Unfortunately, we have a significant technical problem here. The gradient of a function is its *slope*, or its steepness, which can be defined as *rise over run*—that is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: `(y_new - y_old) / (x_new - x_old)`. This gives us a good approximation of the gradient when `x_new` is very similar to `x_old`, meaning that their difference is very small. But accuracy only changes at all when a prediction changes from a 3 to a 7, or vice versa. The problem is that a small change in weights from `x_old` to `x_new` isn't likely to cause any prediction to change, so `(y_new - y_old)` will almost always be 0. In other words, the gradient is 0 almost everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZy2CchGEeFF"
   },
   "source": [
    "正如我们所见，我们需要梯度来使用 SGD 改进我们的模型，并且为了计算梯度，我们需要一些*损失函数*来表示我们的模型有多好。这是因为梯度是衡量损失函数如何随着权重的微小调整而变化的度量。\n",
    "\n",
    "所以，我们需要选择一个损失函数。显而易见的方法是使用准确度，这是我们的指标，也作为我们的损失函数。在这种情况下，我们将计算对每张图像的预测，收集这些值来计算总体准确度，然后计算每个权重相对于总体准确度的梯度。\n",
    "\n",
    "不幸的是，我们在这里遇到了一个重大的技术问题。一个函数的梯度是它的*斜率*，或者说它的陡度，它可以被定义为*上升超过运行*——即函数值上升或下降的程度除以我们改变输入的程度。我们可以在数学上把它写成:`(y_new - y_old) / (x_new - x_old)`。当`x_new`和`x_old`非常相似时，这为我们提供了一个很好的梯度近似值，这意味着它们的差异非常小。但只有当预测值从3变到7时，准确度才会发生变化，反之亦然。问题是，从`x_old`到`x_new`的权重的微小变化不太可能导致任何预测的变化，因此`(y_new - y_old)`几乎总是0。换句话说，梯度几乎处处为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkKPRZ-QsoRg"
   },
   "source": [
    "A very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss function—if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number.\n",
    "\n",
    "> S: In mathematical terms, accuracy is a function that is constant almost everywhere (except at the threshold, 0.5), so its derivative is nil almost everywhere (and infinity at the threshold). This then gives gradients that are 0 or infinite, which are useless for updating the model.\n",
    "\n",
    "Instead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. So what does a \"slightly better prediction\" look like, exactly? Well, in this case, it means that if the correct answer is a 3 the score is a little higher, or if the correct answer is a 7 the score is a little lower.\n",
    "\n",
    "Let's write such a function now. What form does it take?\n",
    "\n",
    "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, `prds`, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n",
    "\n",
    "The purpose of the loss function is to measure the difference between predicted values and the true values — that is, the targets (aka labels). Let's make another argument, `trgts`, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
    "\n",
    "So, for instance, suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence (`0.9`) that the first was a 3, with slight confidence (`0.4`) that the second was a 7, and with fair confidence (`0.2`), but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLGPLcwTEvgY"
   },
   "source": [
    "权重值的非常小的变化通常不会真正改变准确度。这意味着用准确度作为损失函数是没有用的——如果我们这样做，大多数时候我们的梯度实际上是0，模型将无法从该数字中学习。\n",
    "\n",
    ">S:用数学术语来说，准确度是一个几乎在任何地方都是常数的函数(除了阈值0.5)，所以它的导数几乎在任何地方都是零(阈值处为无穷大)。这将提供0或无限的梯度，这对于更新模型是无用的。\n",
    "\n",
    "相反，我们需要一个损失函数，当我们的权重导致稍微更好的预测时，我们就会得到稍微更好的损失。那么，“稍微更好的预测”到底是什么样子的呢?在这种情况下，这意味着如果正确答案是 3 分数会高一点，或者如果正确答案是 7 分数会低一点。\n",
    "\n",
    "现在让我们编写这样一个函数。它采取什么形式？\n",
    "\n",
    "损失函数接收的不是图像本身，而是模型的预测结果。让我们做一个参数，`prds`，值在0到1之间，其中每个值都是对图像为3的预测。它是一个向量(即秩1张量)，在图像上进行索引。\n",
    "\n",
    "损失函数的目的是测量预测值和真实值之间的差异，真实值即目标值(又名标签)。让我们使用另一个参数`trgts`，其值为0或1，表示图像是否为3。它也是一个向量(即另一个秩1张量)，在图像上进行索引。\n",
    "\n",
    "因此，例如，假设我们有三张已知的图像分别是3,7和3。假设我们的模型以很高的置信度（0.9）预测第一个是3，以轻微的置信度（0.4）预测第二个是7，以相当的置信度（0.2），但错误地预测最后一个是7。这意味着我们的损失函数将接收这些值作为其输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "AXFl8ikIsoRg"
   },
   "outputs": [],
   "source": [
    "trgts  = tensor([1,0,1])\n",
    "prds   = tensor([0.9, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeKJp7ApsoRh"
   },
   "source": [
    "Here's a first try at a loss function that measures the distance between `predictions` and `targets`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Mv8NIVbFChd"
   },
   "source": [
    "下面是测量`predictions`和`targets`之间距离的损失函数的第一次尝试:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "bgI9VqSwsoRh"
   },
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5PsipbdsoRh"
   },
   "source": [
    "We're using a new function, `torch.where(a,b,c)`. This is the same as running the list comprehension `[b[i] if a[i] else c[i] for i in range(len(a))]`, except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances.\n",
    "\n",
    "> note: Read the Docs: It's important to learn about PyTorch functions like this, because looping over tensors in Python performs at Python speed, not C/CUDA speed! Try running `help(torch.where)` now to read the docs for this function, or, better still, look it up on the PyTorch documentation site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_8xlTJ5FPhW"
   },
   "source": [
    "我们正在使用一个新的函数`torch.where(a,b,c)`这和运行列表推导`[b[i] if a[i] else c[i] for i in range(len(a))]`是一样的，只是它以C/CUDA速度在张量上工作。简单地说，这个函数会测量每个预测值到1的距离(如果应该是1)和到0的距离(如果应该是0)然后取所有这些距离的均值。\n",
    "\n",
    ">注意:阅读文档:了解这样的PyTorch函数很重要，因为在 Python 中循环张量以 Python 速度执行，而不是C/CUDA速度！现在尝试运行`help(torch.where)`来阅读这个函数的文档，或者更好的做法是在PyTorch网站上查找它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxcXouQJsoRi"
   },
   "source": [
    "Let's try it on our `prds` and `trgts`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_WUDOMZFcid"
   },
   "source": [
    "让我们在我们的`prds`和`trgts`上试试:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "tX2DXa1YsoRi",
    "outputId": "64c52da0-6f98-459c-af5b-7aeaf181bcaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8i2DHW0soRi"
   },
   "source": [
    "You can see that this function returns a lower number when predictions are more accurate, when accurate predictions are more confident (higher absolute values), and when inaccurate predictions are less confident. In PyTorch, we always assume that a lower value of a loss function is better. Since we need a scalar for the final loss, `mnist_loss` takes the mean of the previous tensor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh2D-SDXFlVF"
   },
   "source": [
    "您可以看到，当预测更准确时，当准确的预测更有信心时(较高的绝对值)，以及当不准确的预测不那么有信心时，该函数返回一个较低的数字。在PyTorch中，我们总是假设损失函数的值越低越好。因为我们需要一个标量来表示最终的损失，`mnist_loss`取前一个张量的均值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "IQLIoKI-soRi",
    "outputId": "c8cfaa26-dbab-4b7a-f026-bbba5ea0a157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(prds,trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRai-09DsoRj"
   },
   "source": [
    "For instance, if we change our prediction for the one \"false\" target from `0.2` to `0.8` the loss will go down, indicating that this is a better prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB_vxs8_FrKe"
   },
   "source": [
    "例如，如果我们将一个“错误”目标的预测从`0.2`更改为`0.8`，损失将会下降，这表明这是一个更好的预测:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "W-M7K3I6soRj",
    "outputId": "f7ae607e-33c0-462d-97ef-b14fe82d5de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(tensor([0.9, 0.4, 0.8]),trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIjFWv6-soRj"
   },
   "source": [
    "One problem with `mnist_loss` as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly that—let's take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8gN32VJFxLs"
   },
   "source": [
    "`mnist_loss`当前定义的一个问题是，它假设预测总是在0和1之间。那么，我们需要确保情况确实如此！碰巧有一个函数可以做到这一点——让我们来看看。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E1eCwnRsoRk"
   },
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw-qkdUusoRk"
   },
   "source": [
    "The `sigmoid` function always outputs a number between 0 and 1. It's defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwPpb-65GMFx"
   },
   "source": [
    "`sigmoid`函数总是输出一个介于0和1之间的数字。其定义如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "9M6hK3cAsoRk"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySFg2pP6soRk"
   },
   "source": [
    "Pytorch defines an accelerated version for us, so we don’t really need our own. This is an important function in deep learning, since we often want to ensure values are between 0 and 1. This is what it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te35Gq8-GR40"
   },
   "source": [
    "Pytorch为我们定义了一个加速版本，所以我们真的不需要自己的。这是深度学习中的一个重要函数，因为我们经常想要确保值在0到1之间。这是它的样子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "o3vIi910soRl",
    "outputId": "4b5a2473-0a9a-4cb6-f04d-fe4d279bec8c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8ol1gq-soRl"
   },
   "source": [
    "As you can see, it takes any input value, positive or negative, and smooshes it onto an output value between 0 and 1. It's also a smooth curve that only goes up, which makes it easier for SGD to find meaningful gradients. \n",
    "\n",
    "Let's update `mnist_loss` to first apply `sigmoid` to the inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46G2vPsDGYKB"
   },
   "source": [
    "如您所见，它接受任何输入值(正的或负的)，并将其平滑到0到1之间的输出值上。这也是一条只上升的平滑曲线，这让SGD更容易找到有意义的梯度。\n",
    "\n",
    "让我们更新`mnist_loss`，首先将`sigmoid`应用于输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "tY95y4CesoRl"
   },
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb-QxYPXsoRm"
   },
   "source": [
    "Now we can be confident our loss function will work, even if the predictions are not between 0 and 1. All that is required is that a higher prediction corresponds to higher confidence an image is a 3.\n",
    "\n",
    "Having defined a loss function, now is a good moment to recapitulate why we did this. After all, we already had a metric, which was overall accuracy. So why did we define a loss?\n",
    "\n",
    "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\n",
    "\n",
    "Metrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhPtcQ1BHSk6"
   },
   "source": [
    "现在我们可以确信我们的损失函数是可行的，即使预测不在0到1之间。所需要的只是更高的预测对应更高的置信度，图像是3。\n",
    "\n",
    "定义了损失函数之后，现在是一个很好的时机来总结我们为什么这样做。毕竟，我们已经有了一个指标，即整体准确度。那么我们为什么要定义损失呢?\n",
    "\n",
    "关键的区别在于，指标是为了推动人类的理解，而损失是为了推动自动化学习。为了推动自动学习，损失必须是一个具有有意义的导数的函数。它不能有大的平坦部分和大的跳跃，而是必须是合理平滑的。这就是为什么我们设计了一个损失函数，它会对置信度的微小变化做出反应。这一要求意味着有时它并不能真正反映我们想要实现的目标，而是我们真正目标和可以使用其梯度进行优化的函数之间的折中。为数据集中的每个项目计算损失函数，然后在一个epoch结束时，对所有损失值取平均值，并报告该epoch的总体平均值。\n",
    "\n",
    "另一方面，指标是我们真正关心的数字。这些是在每个 epoch 结束时打印的值，它们告诉我们模型的实际情况。在判断模型的性能时，重要的是我们要学会关注这些指标，而不是损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_SKd1rZsoRm"
   },
   "source": [
    "### SGD and Mini-Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RInRJUD6soRm"
   },
   "source": [
    "Now that we have a loss function that is suitable for driving SGD, we can consider some of the details involved in the next phase of the learning process, which is to change or update the weights based on the gradients. This is called an *optimization step*.\n",
    "\n",
    "In order to take an optimization step we need to calculate the loss over one or more data items. How many should we use? We could calculate it for the whole dataset, and take the average, or we could calculate it for a single data item. But neither of these is ideal. Calculating it for the whole dataset would take a very long time. Calculating it for a single item would not use much information, so it would result in a very imprecise and unstable gradient. That is, you'd be going to the trouble of updating the weights, but taking into account only how that would improve the model's performance on that single item.\n",
    "\n",
    "So instead we take a compromise between the two: we calculate the average loss for a few data items at a time. This is called a *mini-batch*. The number of data items in the mini-batch is called the *batch size*. A larger batch size means that you will get a more accurate and stable estimate of your dataset's gradients from the loss function, but it will take longer, and you will process fewer mini-batches per epoch. Choosing a good batch size is one of the decisions you need to make as a deep learning practitioner to train your model quickly and accurately. We will talk about how to make this choice throughout this book.\n",
    "\n",
    "Another good reason for using mini-batches rather than calculating the gradient on individual data items is that, in practice, we nearly always do our training on an accelerator such as a GPU. These accelerators only perform well if they have lots of work to do at a time, so it's helpful if we can give them lots of data items to work on. Using mini-batches is one of the best ways to do this. However, if you give them too much data to work on at once, they run out of memory—making GPUs happy is also tricky!\n",
    "\n",
    "As we saw in our discussion of data augmentation in <<chapter_production>>, we get better generalization if we can vary things during training. One simple and effective thing we can vary is what data items we put in each mini-batch. Rather than simply enumerating our dataset in order for every epoch, instead what we normally do is randomly shuffle it on every epoch, before we create mini-batches. PyTorch and fastai provide a class that will do the shuffling and mini-batch collation for you, called `DataLoader`.\n",
    "\n",
    "A `DataLoader` can take any Python collection and turn it into an iterator over mini-batches, like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcTvuMdYHa6r"
   },
   "source": [
    "现在我们有了一个适合驱动SGD的损失函数，我们可以考虑下一阶段学习过程中涉及的一些细节，即根据梯度改变或更新权值。这被称为*优化步骤*。\n",
    "\n",
    "为了进行优化步骤，我们需要计算一个或多个数据项的损失。我们应该用多少?我们可以对整个数据集进行计算，然后取平均值，也可以对单个数据项进行计算。但这两者都不是理想的。为整个数据集计算它将花费很长时间。为单个项目计算它不会使用太多信息，因此会导致非常不精确和不稳定的梯度。也就是说，您会遇到更新权重的麻烦，但只考虑这将如何提高模型在该单个项目上的性能。\n",
    "\n",
    "因此，我们在这两者之间进行折中:我们一次计算几个数据项的平均损失。这称为*小批量*。小批量中的数据项数量称为*批量大小*。较大的批大小意味着您将从损失函数中获得对数据集梯度的更准确和稳定的估计，但这将花费更长的时间，并且每个epoch将处理更少的小批。作为深度学习从业者，为了快速准确地训练模型，选择一个好的批量大小是您需要做出的决定之一。我们将在本书中讨论如何做出这个选择。\n",
    "\n",
    "使用小批量而不是计算单个数据项的梯度的另一个很好的理由是，在实践中，我们几乎总是在GPU等加速器上进行训练。这些加速器只有在一次有很多工作要做的情况下才能表现良好，所以如果我们能给它们提供大量的数据项，这将是很有帮助的。使用小批量是最好的方法之一。然而，如果你给他们太多的数据来一次处理，它们就会耗尽内存——让 GPU 满意也很棘手！\n",
    "\n",
    "正如我们在<<chapter_production>>中对数据增强的讨论中看到的那样，如果我们可以在训练过程中改变事物，我们就能得到更好的泛化。我们可以改变的一件简单而有效的事情是我们在每个小批量中放入了哪些数据项。我们不是简单地为每个 epoch 枚举我们的数据集，而是在创建小批量之前，我们通常在每个epoch上随机打乱数据集。PyTorch和fastai提供了一个类，它将为你做洗牌和小批量排序，称为`DataLoader`。\n",
    "\n",
    "`DataLoader`可以接受任何Python集合并将其转换为小批量迭代器，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "iBQTgvD_soRm",
    "outputId": "942a5130-aeb7-465a-a4c1-51d8963b2e8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3, 12,  8, 10,  2]),\n",
       " tensor([ 9,  4,  7, 14,  5]),\n",
       " tensor([ 1, 13,  0,  6, 11])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = range(15)\n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH5ENsaZsoRn"
   },
   "source": [
    "For training a model, we don't just want any Python collection, but a collection containing independent and dependent variables (that is, the inputs and targets of the model). A collection that contains tuples of independent and dependent variables is known in PyTorch as a `Dataset`. Here's an example of an extremely simple `Dataset`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jizVRT0AHmF2"
   },
   "source": [
    "对于训练模型，我们不只是想要任何Python集合，而是一个包含自变量和因变量（即模型的输入和目标）的集合。包含自变量和因变量元组的集合在PyTorch中称为`Dataset`。这是一个非常简单的`Dataset`示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "uSgND4iOsoRn",
    "outputId": "d7fbe306-23c2-40f2-9cd8-83d2bb5f127d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzeC9UVUsoRn"
   },
   "source": [
    "When we pass a `Dataset` to a `DataLoader` we will get back mini-batches which are themselves tuples of tensors representing batches of independent and dependent variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkR5HgzEHwqo"
   },
   "source": [
    "当我们将`Dataset`传递给`DataLoader`时，我们将返回小批量，它们本身是表示成批的自变量和因变量的张量元组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "T0V1xTcJsoRo",
    "outputId": "2211cf37-e093-4cdb-8896-5c20e58c329d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),\n",
       " (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),\n",
       " (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),\n",
       " (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),\n",
       " (tensor([2, 4]), ('c', 'e'))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=6, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTtT9PAZsoRo"
   },
   "source": [
    "We are now ready to write our first training loop for a model using SGD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIRo-6uUH3uo"
   },
   "source": [
    "现在我们已经准备好使用SGD编写模型的第一个训练循环了!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bXo86UjsoRo"
   },
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWAD_RkMI7TX"
   },
   "source": [
    "## 把它们放在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhBglZ0QsoRo"
   },
   "source": [
    "It's time to implement the process we saw in <<gradient_descent>>. In code, our process will be implemented something like this for each epoch:\n",
    "\n",
    "```python\n",
    "for x,y in dl:\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred, y)\n",
    "    loss.backward()\n",
    "    parameters -= parameters.grad * lr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaQImPo2JAT8"
   },
   "source": [
    "是时候实现我们在<<gradient_descent>>中看到的流程了。在代码中，我们的进程将在每个epoch中实现如下内容：\n",
    "\n",
    "```python\n",
    "for x,y in dl:\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred, y)\n",
    "    loss.backward()\n",
    "    parameters -= parameters.grad * lr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48FT43C6soRo"
   },
   "source": [
    "First, let's re-initialize our parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbE1oK2vJOLl"
   },
   "source": [
    "首先，让我们重新初始化我们的参数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "b_lGFQCqsoRp"
   },
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox9fEDf3soRp"
   },
   "source": [
    "A `DataLoader` can be created from a `Dataset`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3dvERKTX2CO"
   },
   "source": [
    "可以从`Dataset`创建`DataLoader`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "jWGsJjWdsoRp",
    "outputId": "d91586f1-0033-4eb9-d4b5-55e8d14e6f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTZ60dhrsoRp"
   },
   "source": [
    "We'll do the same for the validation set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mR63dwujX8q1"
   },
   "source": [
    "我们将对验证集执行相同的操作:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "w7w9FGJTsoRq"
   },
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTLpI_SEsoRq"
   },
   "source": [
    "Let's create a mini-batch of size 4 for testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWdjRUa0YBJS"
   },
   "source": [
    "让我们创建一个大小为4的小批量进行测试:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "iwaoNmQjsoRq",
    "outputId": "29985ee8-570b-4f54-d750-1a24ced9f391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "m_mXy2rpsoRq",
    "outputId": "dade1069-582d-4419-f63f-4818063266ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1876],\n",
       "        [-8.3973],\n",
       "        [ 2.5000],\n",
       "        [-4.9473]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "kNhPEl7xsoRq",
    "outputId": "5d3e4a92-0049-46e0-8ac4-7a96e7b86f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7419, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApbY1dkEsoRr"
   },
   "source": [
    "Now we can calculate the gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK4sEz4WYJPK"
   },
   "source": [
    "现在我们可以计算梯度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "UBxg9ouIsoRr",
    "outputId": "a967f3f5-9bba-4494-f725-32a18969221c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MtbXTLesoRr"
   },
   "source": [
    "Let's put that all in a function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVE5QKUWYNiG"
   },
   "source": [
    "让我们把这些都放在一个函数中:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "8AcAbB37soRr"
   },
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZzFAQEgsoRs"
   },
   "source": [
    "and test it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNN9a9GtYR1n"
   },
   "source": [
    "并测试它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "-GgacRhUsoRs",
    "outputId": "aeaa007c-6b31-4770-ece7-f2cd5c6591c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0121), tensor([-0.0840]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p24ZoNFtsoRs"
   },
   "source": [
    "But look what happens if we call it twice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDqem7ZGYWN3"
   },
   "source": [
    "但是看看如果我们调用它两次会发生什么:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "pAFns5TxsoRs",
    "outputId": "e0b9519f-538b-47d2-f152-3186c52c5c66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0182), tensor([-0.1260]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7mWj3y-soRt"
   },
   "source": [
    "The gradients have changed! The reason for this is that `loss.backward` actually *adds* the gradients of `loss` to any gradients that are currently stored. So, we have to set the current gradients to 0 first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR3Nv4ecYczt"
   },
   "source": [
    "梯度改变了!原因就是这种`loss.backward`实际上是将`loss`的梯度加到当前存储的任何梯度上。因此，我们必须首先将当前的梯度设置为0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "j7Aru1JZsoRt"
   },
   "outputs": [],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeGVKF1bsoRt"
   },
   "source": [
    "> note: Inplace Operations: Methods in PyTorch whose names end in an underscore modify their objects _in place_. For instance, `bias.zero_()` sets all elements of the tensor `bias` to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm1ulBn6ZGgY"
   },
   "source": [
    "注意：就地操作：PyTorch中名称以下划线结尾的方法就地修改它们的对象。例如，`bias.zero_()`将张量`bias`的所有元素设为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vlpAM-jsoRt"
   },
   "source": [
    "Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch! If we assign to the `data` attribute of a tensor then PyTorch will not take the gradient of that step. Here's our basic training loop for an epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UDHOWkoZVkq"
   },
   "source": [
    "我们唯一剩下的步骤是根据梯度和学习率更新权重和偏差。当我们这样做时，我们必须告诉PyTorch不要也采用这一步的梯度——否则当我们尝试在下一批计算导数时，事情会变得非常混乱!如果我们给一个张量的`data`属性赋值，那么PyTorch将不会采取该步骤的梯度。以下是我们一个epoch的基本训练循环:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "e9dq9_iEsoRt"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwxCOfvUsoRu"
   },
   "source": [
    "We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCL9qCdycJRt"
   },
   "source": [
    "我们还想通过查看验证集的准确度来检查我们所做的工作。要确定一个输出代表3还是7，我们只需检查它是否大于0。所以我们可以计算每个项目的准确性(使用广播，所以没有循环!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "nmCIhw0XsoRu",
    "outputId": "1d2e3675-3a73-40c9-e9f0-a891596cfbc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlMzHExHsoRu"
   },
   "source": [
    "That gives us this function to calculate our validation accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiZf7cBWcOkj"
   },
   "source": [
    "这给了我们这个函数来计算我们的验证准确度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "u7WnhQcRsoRu"
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjnEMt5MsoRv"
   },
   "source": [
    "We can check it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsV5oZYfc2my"
   },
   "source": [
    "我们可以检查它是否有效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Bu0O5xUEsoRv",
    "outputId": "40c8237d-930b-4f4f-87a0-5ab6600a96f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C__3UMowsoRv"
   },
   "source": [
    "and then put the batches together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g8BflL0gAf8"
   },
   "source": [
    "然后把批次放在一起:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "fblPD44WsoRv"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Fot9uHKisoRv",
    "outputId": "55947a6f-bf4e-46e5-8f2e-bbda7c5e67cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUve3zYNsoRw"
   },
   "source": [
    "That's our starting point. Let's train for one epoch, and see if the accuracy improves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBg9-TNGgGQx"
   },
   "source": [
    "这是我们的出发点。让我们训练一个 epoch，看看准确率是否有所提高："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "LbgoBFEFsoRw",
    "outputId": "8e194ae6-db75-4167-8030-f7bda5a89d93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edmBNoiPsoRx"
   },
   "source": [
    "Then do a few more:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBX3NlBqgKp4"
   },
   "source": [
    "然后再做几次:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "6Vf-ajZhsoRx",
    "outputId": "363be025-c3ce-459b-8ec9-4910115fdc50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266 0.89 0.9184 0.9277 0.9399 0.9467 0.9506 0.9526 0.956 0.9579 0.9599 0.9609 0.9614 0.9619 0.9633 0.9638 0.9648 0.9658 0.9672 0.9677 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsSTOKl6soRx"
   },
   "source": [
    "Looking good! We're already about at the same accuracy as our \"pixel similarity\" approach, and we've created a general-purpose foundation we can build on. Our next step will be to create an object that will handle the SGD step for us. In PyTorch, it's called an *optimizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhwUA6QDgPX_"
   },
   "source": [
    "看起来不错！我们已经与我们的“像素相似度”方法具有相同的准确度，并且我们已经创建了一个可以构建的通用基础。我们的下一步将是创建一个对象来为我们处理SGD步骤。在PyTorch中，它被称为*优化器*。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27SHPMRssoRy"
   },
   "source": [
    "### Creating an Optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BSJtNR9gmoT"
   },
   "source": [
    "### 创建一个优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yuIg9-CsoRy"
   },
   "source": [
    "Because this is such a general foundation, PyTorch provides some useful classes to make it easier to implement. The first thing we can do is replace our `linear1` function with PyTorch's `nn.Linear` module. A *module* is an object of a class that inherits from the PyTorch `nn.Module` class. Objects of this class behave identically to standard Python functions, in that you can call them using parentheses and they will return the activations of a model.\n",
    "\n",
    "`nn.Linear` does the same thing as our `init_params` and `linear` together. It contains both the *weights* and *biases* in a single class. Here's how we replicate our model from the previous section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrzTxlwfgrfQ"
   },
   "source": [
    "因为这是一个通用的基础，PyTorch提供了一些有用的类，使其更容易实现。我们可以做的第一件事是用PyTorch的`nn.Linear`模块替换我们的`linear1`函数。*模块*是继承自PyTorch的`nn.Module`的类的对象。这个类的对象的行为与标准Python函数相同，因为你可以使用括号调用它们，它们将返回模型的激活。\n",
    "\n",
    "`nn.Linear`与我们的`init_params`和`linear`一起做同样的事情。它包含了单个类中的*权重*和*偏差*。以下是我们如何复制上一节的模型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "yNAKltTLsoRy"
   },
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1YLaEYWsoRy"
   },
   "source": [
    "Every PyTorch module knows what parameters it has that can be trained; they are available through the `parameters` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1q8ESjjhsLN"
   },
   "source": [
    "每个PyTorch模块都知道它有哪些可以训练的参数；它们可以通过`parameters`方法获得:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "fOEpSDBCsoRy",
    "outputId": "d4922f85-ade8-4b9c-be6f-1ba4f8e0f521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_vEKwUXsoRz"
   },
   "source": [
    "We can use this information to create an optimizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ6cHo6Hh3O7"
   },
   "source": [
    "我们可以使用这些信息来创建一个优化器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "YydizoUesoRz"
   },
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7nUtIFXsoRz"
   },
   "source": [
    "We can create our optimizer by passing in the model's parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olLfjP5qiNDs"
   },
   "source": [
    "我们可以通过传入模型的参数来创建优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "o9-iYCvtsoRz"
   },
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48t4qqPfsoR0"
   },
   "source": [
    "Our training loop can now be simplified to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tzkw97U9iRCz"
   },
   "source": [
    "我们的训练循环现在可以简化为:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "CBUU7lzhsoR0"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIsh3nCcsoR0"
   },
   "source": [
    "Our validation function doesn't need to change at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oiqhr_jXiU3r"
   },
   "source": [
    "我们的验证函数根本不需要改变:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "dwBv4oSMsoR0",
    "outputId": "224e8ad7-a1b7-43b7-9964-d3b0d94fbffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.461"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70Ghk8qasoR0"
   },
   "source": [
    "Let's put our little training loop in a function, to make things simpler:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMlz2O_FiZBx"
   },
   "source": [
    "让我们把我们的小训练循环放在一个函数中，让事情变得更简单:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "bHGMHxmusoR1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qk82LlmsoR1"
   },
   "source": [
    "The results are the same as in the previous section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gml6KHdidBL"
   },
   "source": [
    "结果与上一节相同:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "NuRaMHxIsoR1",
    "outputId": "c3ea90c5-3674-4e2e-a4cf-9e27160de24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.7686 0.8555 0.9136 0.9346 0.9482 0.957 0.9634 0.9658 0.9678 0.9697 0.9717 0.9736 0.9746 0.9761 0.977 0.9775 0.9775 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsRWG4vXsoR1"
   },
   "source": [
    "fastai provides the `SGD` class which, by default, does the same thing as our `BasicOptim`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU32TFa0ig1W"
   },
   "source": [
    "fastai提供了`SGD`类，默认情况下，它与我们的`BasicOptim`做同样的事情："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "27U7HOf7soR1",
    "outputId": "34ff6e44-9ae4-4d3d-bbaf-470d3dec5e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8179 0.8496 0.9141 0.9346 0.9482 0.957 0.9619 0.9658 0.9673 0.9692 0.9712 0.9741 0.9751 0.9761 0.9775 0.9775 0.978 0.9785 0.979 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpF0QvRNsoR2"
   },
   "source": [
    "fastai also provides `Learner.fit`, which we can use instead of `train_model`. To create a `Learner` we first need to create a `DataLoaders`, by passing in our training and validation `DataLoader`s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gys8KztinYs"
   },
   "source": [
    "fastai也提供`Learner.fit`，我们可以用它来代替`train_model`。要创建一个`Learner`，我们首先需要通过传递我们的训练和验证`Dataloader`创建一个`Dataloaders`，:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "RMKdL4phsoR2"
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKz-PqfBsoR2"
   },
   "source": [
    "To create a `Learner` without using an application (such as `vision_learner`) we need to pass in all the elements that we've created in this chapter: the `DataLoaders`, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb94RupLjALj"
   },
   "source": [
    "要创建一个不使用应用程序(如`vision_learner`)的`Learner`，我们需要传入本章中创建的所有元素:`Dataloaders`、模型、优化函数(将传递参数)、损失函数，以及可选的任何要打印的指标:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "pa5ZU2YpsoR2"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmCNc3ussoR3"
   },
   "source": [
    "Now we can call `fit`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PitdRAqKjQiA"
   },
   "source": [
    "现在我们可以调用`fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "o0wCO_P6soR3",
    "outputId": "a6f70a4c-b27b-4225-bc73-4988a0ac9c18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.503144</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.429828</td>\n",
       "      <td>0.248517</td>\n",
       "      <td>0.777233</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161680</td>\n",
       "      <td>0.155361</td>\n",
       "      <td>0.861629</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.097722</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.950442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.050799</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.037788</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxY5io-rsoR3"
   },
   "source": [
    "As you can see, there's nothing magic about the PyTorch and fastai classes. They are just convenient pre-packaged pieces that make your life a bit easier! (They also provide a lot of extra functionality we'll be using in future chapters.)\n",
    "\n",
    "With these classes, we can now replace our linear model with a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_yU8-ocjWxW"
   },
   "source": [
    "正如您所看到的，PyTorch和fastai类并没有什么神奇之处。它们只是方便的预包装件，让你的生活更轻松!(它们还提供了很多额外的功能，我们将在以后的章节中使用。)\n",
    "\n",
    "有了这些类，我们现在可以用神经网络替换我们的线性模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqrhkgz_soR3"
   },
   "source": [
    "## Adding a Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQDZSvV4jcln"
   },
   "source": [
    "## 添加非线性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_4_IT7JsoR4"
   },
   "source": [
    "So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.\n",
    "\n",
    "Here is the entire definition of a basic neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Unfhx_WOjh1a"
   },
   "source": [
    "到目前为止，我们已经有了一个优化函数参数的通用过程，并且我们已经在一个非常无聊的函数上进行了试验:一个简单的线性分类器。线性分类器的功能非常有限。为了使它变得更复杂(并能够处理更多的任务)，我们需要在两个线性分类器之间添加一些非线性的东西——这就是我们的神经网络。\n",
    "\n",
    "以下是基本神经网络的完整定义:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "SPqkEMO0soR4"
   },
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vFSBwUCsoR4"
   },
   "source": [
    "That's it! All we have in `simple_net` is two linear classifiers with a `max` function between them.\n",
    "\n",
    "Here, `w1` and `w2` are weight tensors, and `b1` and `b2` are bias tensors; that is, parameters that are initially randomly initialized, just like we did in the previous section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwHhWafSmtOR"
   },
   "source": [
    "就是这样！在`simple_net`中，我们只有两个线性分类器，它们之间有一个`max`函数。\n",
    "\n",
    "在这里，`w1`和`w2`是权重张量，`b1`和`b2`是偏差张量;也就是说，参数最初是随机初始化的，就像我们在上一节中所做的那样:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "WohKltKmsoR4"
   },
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSZsopChsoR4"
   },
   "source": [
    "The key point about this is that `w1` has 30 output activations (which means that `w2` must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that `30` to anything you like, to make the model more or less complex.\n",
    "\n",
    "That little function `res.max(tensor(0.0))` is called a *rectified linear unit*, also known as *ReLU*. We think we can all agree that *rectified linear unit* sounds pretty fancy and complicated... But actually, there's nothing more to it than `res.max(tensor(0.0))`—in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as `F.relu`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNzdZozCm6dJ"
   },
   "source": [
    "这里的关键点在于`w1`有30个输出激活(这意味着`w2`必须有30个输入激活，所以它们是匹配的)。这意味着第一层可以构建30个不同的特征，每个特征代表一些不同的像素组合。您可以将`30`更改为任何您喜欢的值，以使模型更复杂或更简单。\n",
    "\n",
    "这个小函数`res.max(tensor(0.0))`被称为*整流线性单元*，也被称为*ReLU*。我们认为我们都同意*整流线性单元*听起来很花哨和复杂…但实际上，它除了`res.max(tensor(0.0))`没有别的了——换句话说，就是用零替换每个负数。这个小功能在PyTorch中也可用`F.relu`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "gIqjVnhfsoR5",
    "outputId": "06de720c-8953-42a7-9262-9ae9709fbf23"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "botWROassoR5"
   },
   "source": [
    "> J: There is an enormous amount of jargon in deep learning, including terms like _rectified linear unit_. The vast vast majority of this jargon is no more complicated than can be implemented in a short line of code, as we saw in this example. The reality is that for academics to get their papers published they need to make them sound as impressive and sophisticated as possible. One of the ways that they do that is to introduce jargon. Unfortunately, this has the result that the field ends up becoming far more intimidating and difficult to get into than it should be. You do have to learn the jargon, because otherwise papers and tutorials are not going to mean much to you. But that doesn't mean you have to find the jargon intimidating. Just remember, when you come across a word or phrase that you haven't seen before, it will almost certainly turn out to be referring to a very simple concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1HUQs1RngB5"
   },
   "source": [
    ">J:深度学习中有大量的术语，包括 _整流线性单元_ 这样的术语。正如我们在这个例子中看到的，绝大多数术语并不比一小行代码更复杂。现实是，对于学者来说，要发表他们的论文，他们需要让它们听起来尽可能令人印象深刻和复杂。他们这样做的方法之一是引入术语。不幸的是，这导致了该领域最终变得更加令人生畏和难以进入。你必须学习术语，否则论文和教程对你来说没有多大意义。但这并不意味着你必须对术语感到恐惧。只要记住，当你遇到一个你以前没见过的单词或短语时，它几乎肯定指的是一个非常简单的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXCLbb_0soR5"
   },
   "source": [
    "The basic idea is that by using more linear layers, we can have our model do more computation, and therefore model more complex functions. But there's no point just putting one linear layer directly after another one, because when we multiply things together and then add them up multiple times, that could be replaced by multiplying different things together and adding them up just once! That is to say, a series of any number of linear layers in a row can be replaced with a single linear layer with a different set of parameters.\n",
    "\n",
    "But if we put a nonlinear function between them, such as `max`, then this is no longer true. Now each linear layer is actually somewhat decoupled from the other ones, and can do its own useful work. The `max` function is particularly interesting, because it operates as a simple `if` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evo2Zn6vnma-"
   },
   "source": [
    "其基本思想是，通过使用更多的线性层，我们可以让我们的模型进行更多的计算，从而对更复杂的函数进行建模。但是，把一个线性层直接放在另一个线性层之后是没有意义的，因为将事物相乘在一起，然后多次相加时，可以通过将不同的事物相乘并相加来替换它们！也就是说，一行中一系列任意数量的线性层可以替换为具有不同参数集的单个线性层。\n",
    "\n",
    "但是如果我们在它们之间放一个非线性函数，比如`max`，那么这个就不成立了。现在每一个线性层实际上都是与其他层解耦的，并且可以做自己有用的工作。`max`函数特别有趣，因为它作为一个简单的`if`语句运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYk5FbGdsoR5"
   },
   "source": [
    "> S: Mathematically, we say the composition of two linear functions is another linear function. So, we can stack as many linear classifiers as we want on top of each other, and without nonlinear functions between them, it will just be the same as one linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epf3Ln2_nwhx"
   },
   "source": [
    ">S:数学上，我们说两个线性函数的复合是另一个线性函数。所以，我们可以把任意多的线性分类器堆叠在一起，它们之间没有非线性函数，就和一个线性分类器一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnWp5HOWsoR6"
   },
   "source": [
    "Amazingly enough, it can be mathematically proven that this little function can solve any computable problem to an arbitrarily high level of accuracy, if you can find the right parameters for `w1` and `w2` and if you make these matrices big enough. For any arbitrarily wiggly function, we can approximate it as a bunch of lines joined together; to make it closer to the wiggly function, we just have to use shorter lines. This is known as the *universal approximation theorem*. The three lines of code that we have here are known as *layers*. The first and third are known as *linear layers*, and the second line of code is known variously as a *nonlinearity*, or *activation function*.\n",
    "\n",
    "Just like in the previous section, we can replace this code with something a bit simpler, by taking advantage of PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFHMACKyn3l0"
   },
   "source": [
    "令人惊讶的是，数学上可以证明，这个小函数可以以任意高水平的准确度度解决任何可计算的问题，如果你能找到`w1`和`w2`的正确参数并且使这些矩阵足够大。对于任何任意摆动的函数，我们可以把它近似为一串连接在一起的线;为了让它更接近摆动函数，我们只需要用更短的线。这就是所谓的*普遍逼近定理*。我们这里的三行代码被称为*层*。第一行和第三行被称为*线性层*，第二行代码被称为*非线性*或*激活函数*。\n",
    "\n",
    "就像上一节一样，我们可以利用PyTorch，用更简单的代码替换这段代码:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "2HPmNSFgsoR6"
   },
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btQ2sV9RsoR6"
   },
   "source": [
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn.\n",
    "\n",
    "`nn.ReLU` is a PyTorch module that does exactly the same thing as the `F.relu` function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing `F` with `nn` and changing the capitalization. When using `nn.Sequential`, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see `nn.ReLU()` in this example. \n",
    "\n",
    "Because `nn.Sequential` is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF5LTqxzoCTb"
   },
   "source": [
    "`nn.Sequential`创建一个模块，该模块将依次调用列出的每一层或函数。\n",
    "\n",
    "`nn.ReLU`是一个PyTorch模块，它做的事情与`F.relu`函数完全相同。模型中可以出现的大多数函数也具有相同的形式，即模块。通常，就是用`nn`替换`F`并更改大写的情况。当使用`nn.Sequential`，PyTorch要求我们使用模块版本。由于模块是类，我们必须实例化它们，这就是为什么你会在本例中看到`nn.ReLU()`。\n",
    "\n",
    "因为`nn.Sequential`是一个模块，我们可以获取它的参数，这将返回它所包含的所有模块的所有参数的列表。让我们试试看！由于这是一个更深的模型，我们将使用较低的学习率和更多的epoch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "E0U3YHTnsoR7"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "71CnFB-QsoR7",
    "outputId": "62b39887-8063-40fa-f321-eea8c3c22383"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.333021</td>\n",
       "      <td>0.396112</td>\n",
       "      <td>0.512267</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152461</td>\n",
       "      <td>0.235238</td>\n",
       "      <td>0.797350</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083573</td>\n",
       "      <td>0.117471</td>\n",
       "      <td>0.911678</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054309</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.940628</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>0.051490</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030123</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.041218</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.029352</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.027788</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.025022</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.022922</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PU262Y-soSC"
   },
   "source": [
    "We're not showing the 40 lines of output here to save room; the training process is recorded in `learn.recorder`, with the table of output stored in the `values` attribute, so we can plot the accuracy over training as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtQkZqeyou6J"
   },
   "source": [
    "为了节省空间，我们没有在这里显示40行输出；训练过程记录在`learn.recorder`，输出表存储在`values`属性中，因此我们可以将训练的准确度绘制为:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "jsshqarTsoSD",
    "outputId": "4fe89c6b-4f74-4c22-9118-d7a9962e33ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr_fZJn7soSD"
   },
   "source": [
    "And we can view the final accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB9fDViCo7mD"
   },
   "source": [
    "我们可以看到最终的准确度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "VeH9cqs-soSD",
    "outputId": "65673f72-8a56-4a66-ac0f-bd068f924463"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98233562707901"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwPM8wvnsoSE"
   },
   "source": [
    "At this point we have something that is rather magical:\n",
    "\n",
    "1. A function that can solve any problem to any level of accuracy (the neural network) given the correct set of parameters\n",
    "1. A way to find the best set of parameters for any function (stochastic gradient descent)\n",
    "\n",
    "This is why deep learning can do things which seem rather magical, such fantastic things. Believing that this combination of simple techniques can really solve any problem is one of the biggest steps that we find many students have to take. It seems too good to be true—surely things should be more difficult and complicated than this? Our recommendation: try it out! We just tried it on the MNIST dataset and you have seen the results. And since we are doing everything from scratch ourselves (except for calculating the gradients) you know that there is no special magic hiding behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRC4cNeXo_U7"
   },
   "source": [
    "在这一点上，我们有一些相当神奇的东西:\n",
    "\n",
    "1. 给定正确的参数集的情况下，可以以任何精度（神经网络）解决任何问题的函数\n",
    "1. 一种为任意函数找到最佳参数集的方法(随机梯度下降)\n",
    "\n",
    "这就是为什么深度学习可以做一些看起来相当神奇的事情，如此奇妙的事情。相信这种简单技术的组合可以真正解决任何问题，这是我们发现许多学生必须采取的最大步骤之一。这似乎好得令人难以置信——事情肯定比这更困难和复杂吗？我们的建议是:试试看！我们刚刚在MNIST数据集上尝试了一下，你已经看到了结果。因为我们自己从头开始做所有的事情(除了计算梯度)，所以你知道并没有什么特殊的魔法隐藏在幕后。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjEE-2rRsoSE"
   },
   "source": [
    "### Going Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Brc850CpJ1C"
   },
   "source": [
    "### 越来越深"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roXhnn6osoSE"
   },
   "source": [
    "There is no need to stop at just two linear layers. We can add as many as we want, as long as we add a nonlinearity between each pair of linear layers. As you will learn, however, the deeper the model gets, the harder it is to optimize the parameters in practice. Later in this book you will learn about some simple but brilliantly effective techniques for training deeper models.\n",
    "\n",
    "We already know that a single nonlinearity with two linear layers is enough to approximate any function. So why would we use deeper models? The reason is performance. With a deeper model (that is, one with more layers) we do not need to use as many parameters; it turns out that we can use smaller matrices with more layers, and get better results than we would get with larger matrices, and few layers.\n",
    "\n",
    "That means that we can train the model more quickly, and it will take up less memory. In the 1990s researchers were so focused on the universal approximation theorem that very few were experimenting with more than one nonlinearity. This theoretical but not practical foundation held back the field for years. Some researchers, however, did experiment with deep models, and eventually were able to show that these models could perform much better in practice. Eventually, theoretical results were developed which showed why this happens. Today, it is extremely unusual to find anybody using a neural network with just one nonlinearity.\n",
    "\n",
    "Here is what happens when we train an 18-layer model using the same approach we saw in <<chapter_intro>>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJVVRzzqpR_T"
   },
   "source": [
    "没有必要只停留在两个线性层。我们想加多少就加多少，只要我们在每对线性层之间加一个非线性。然而，正如您将了解到的那样，模型越深入，在实践中优化参数就越困难。在本书的后面部分，您将了解一些用于训练更深层次模型的简单但非常有效的技术。\n",
    "\n",
    "我们已经知道具有两个线性层的单个非线性足以逼近任何函数。那么我们为什么要使用更深层次的模型呢?原因在于性能。对于更深层次的模型(也就是说，有更多层的模型)，我们不需要使用太多的参数；事实证明，我们可以使用具有更多层的更小的矩阵，并且获得比具有更大矩阵和更少层的更好的结果。\n",
    "\n",
    "这意味着我们可以更快地训练模型，并且占用更少的内存。在20世纪90年代，研究人员如此专注于普遍逼近定理，以至于很少有人对不止一个非线性进行实验。这种理论而非实践的基础多年来一直阻碍着该领域的发展。然而，一些研究人员确实对深度模型进行了实验，最终能够证明这些模型在实践中可以表现得更好。最终，理论结果显示了为什么会发生这种情况。今天，很少有人使用只有一个非线性的神经网络。\n",
    "\n",
    "以下是我们使用<<chapter_intro>>中看到的相同方法训练18层模型时发生的情况:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "ibn76jfbsoSF",
    "outputId": "e5b3c97a-214f-4758-c3d4-d86fb1ffd783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.110912</td>\n",
       "      <td>0.023535</td>\n",
       "      <td>0.995093</td>\n",
       "      <td>12:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = vision_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEjAJdz4soSF"
   },
   "source": [
    "Nearly 100% accuracy! That's a big difference compared to our simple neural net. But as you'll learn in the remainder of this book, there are just a few little tricks you need to use to get such great results from scratch yourself. You already know the key foundational pieces. (Of course, even once you know all the tricks, you'll nearly always want to work with the pre-built classes provided by PyTorch and fastai, because they save you having to think about all the little details yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f8AwsTNpcpI"
   },
   "source": [
    "近100%的准确性!与我们简单的神经网络相比，这是一个很大的不同。但是，正如你将在本书的其余部分学到的那样，你只需要使用一些小技巧，就可以自己从头开始获得如此出色的结果。你已经知道了关键的基础部分。(当然，即使你知道了所有的技巧，你几乎总是想使用PyTorch和fastai提供的预构建类，因为它们省去了你自己考虑所有小细节的麻烦。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuUD1pQesoSF"
   },
   "source": [
    "## Jargon Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZd8Q5dEpi2U"
   },
   "source": [
    "## 术语回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpxfeIy8soSF"
   },
   "source": [
    "Congratulations: you now know how to create and train a deep neural network from scratch! We've gone through quite a few steps to get to this point, but you might be surprised at how simple it really is.\n",
    "\n",
    "Now that we are at this point, it is a good opportunity to define, and review, some jargon and key concepts.\n",
    "\n",
    "A neural network contains a lot of numbers, but they are only of two types: numbers that are calculated, and the parameters that these numbers are calculated from. This gives us the two most important pieces of jargon to learn:\n",
    "\n",
    "- Activations:: Numbers that are calculated (both by linear and nonlinear layers)\n",
    "- Parameters:: Numbers that are randomly initialized, and optimized (that is, the numbers that define the model)\n",
    "\n",
    "We will often talk in this book about activations and parameters. Remember that they have very specific meanings. They are numbers. They are not abstract concepts, but they are actual specific numbers that are in your model. Part of becoming a good deep learning practitioner is getting used to the idea of actually looking at your activations and parameters, and plotting them and testing whether they are behaving correctly.\n",
    "\n",
    "Our activations and parameters are all contained in *tensors*. These are simply regularly shaped arrays—for example, a matrix. Matrices have rows and columns; we call these the *axes* or *dimensions*. The number of dimensions of a tensor is its *rank*. There are some special tensors:\n",
    "\n",
    "- Rank zero: scalar\n",
    "- Rank one: vector\n",
    "- Rank two: matrix\n",
    "\n",
    "A neural network contains a number of layers. Each layer is either *linear* or *nonlinear*. We generally alternate between these two kinds of layers in a neural network. Sometimes people refer to both a linear layer and its subsequent nonlinearity together as a single layer. Yes, this is confusing. Sometimes a nonlinearity is referred to as an *activation function*.\n",
    "\n",
    "<<dljargon1>> summarizes the key concepts related to SGD.\n",
    "\n",
    "```asciidoc\n",
    "[[dljargon1]]\n",
    ".Deep learning vocabulary\n",
    "[options=\"header\"]\n",
    "|=====\n",
    "| Term | Meaning\n",
    "|ReLU | Function that returns 0 for negative numbers and doesn't change positive numbers.\n",
    "|Mini-batch | A small group of inputs and labels gathered together in two arrays. A gradient descent step is updated on this batch (rather than a whole epoch).\n",
    "|Forward pass | Applying the model to some input and computing the predictions.\n",
    "|Loss | A value that represents how well (or badly) our model is doing.\n",
    "|Gradient | The derivative of the loss with respect to some parameter of the model.\n",
    "|Backward pass | Computing the gradients of the loss with respect to all model parameters.\n",
    "|Gradient descent | Taking a step in the directions opposite to the gradients to make the model parameters a little bit better.\n",
    "|Learning rate | The size of the step we take when applying SGD to update the parameters of the model.\n",
    "|=====\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZIfmjLVpqhX"
   },
   "source": [
    "恭喜:您现在知道如何从头开始创建和训练深度神经网络了！我们已经完成了相当多的步骤才达到这一点，但您可能会惊讶于它实际上是多么简单。\n",
    "\n",
    "既然我们已经到了这一步，现在是定义和回顾一些术语和关键概念的好机会。\n",
    "\n",
    "神经网络包含很多数字，但它们只有两种类型:计算的数字，以及计算这些数字的参数。这给了我们两个最重要的术语需要学习:\n",
    "\n",
    "- Activations::计算的数字(通过线性和非线性层)\n",
    "- Parameters::随机初始化和优化的数字(即定义模型的数字)\n",
    "\n",
    "我们将经常在本书中讨论激活和参数。记住，它们有非常具体的含义。他们是数字。它们不是抽象的概念，而是模型中实际存在的具体数字。成为一名优秀的深度学习实践者的一部分是习惯于实际查看您的激活和参数，绘制它们并测试它们是否行为正确。\n",
    "\n",
    "我们的激活和参数都包含在*张量*中。这些只是规则形状的数组——例如，矩阵。矩阵有行和列;我们称这些为*轴*或*维度*。一个张量的维数就是它的*秩*。有一些特殊的张量:\n",
    "\n",
    "0级:标量\n",
    "1级:向量\n",
    "2级:矩阵\n",
    "\n",
    "神经网络包含许多层。每一层都是*线性*或*非线性*的。在神经网络中，我们通常交替使用这两种层。有时人们把线性层和随后的非线性层一起称为单层。是的，这令人困惑。有时非线性被称为*激活函数*。\n",
    "\n",
    "<<dljargon1>>总结了SGD相关的关键概念。\n",
    "\n",
    "```asciidoc\n",
    "[[dljargon1]]\n",
    ".Deep learning vocabulary\n",
    "[options=\"header\"]\n",
    "|=====\n",
    "| Term | Meaning\n",
    "|ReLU | Function that returns 0 for negative numbers and doesn't change positive numbers.\n",
    "|Mini-batch | A small group of inputs and labels gathered together in two arrays. A gradient descent step is updated on this batch (rather than a whole epoch).\n",
    "|Forward pass | Applying the model to some input and computing the predictions.\n",
    "|Loss | A value that represents how well (or badly) our model is doing.\n",
    "|Gradient | The derivative of the loss with respect to some parameter of the model.\n",
    "|Backward pass | Computing the gradients of the loss with respect to all model parameters.\n",
    "|Gradient descent | Taking a step in the directions opposite to the gradients to make the model parameters a little bit better.\n",
    "|Learning rate | The size of the step we take when applying SGD to update the parameters of the model.\n",
    "|=====\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVDUv6N0soSG"
   },
   "source": [
    "> note: _Choose Your Own Adventure_ Reminder: Did you choose to skip over chapters 2 & 3, in your excitement to peek under the hood? Well, here's your reminder to head back to chapter 2 now, because you'll be needing to know that stuff very soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzBwAFpFr3Jj"
   },
   "source": [
    ">注意: _选择你自己的冒险_提醒:你是否选择跳过第2章和第3章，兴奋地从底层偷看？这里提醒您现在回到第 2 章，因为您很快就会需要了解这些内容！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6veNOIIZsoSG"
   },
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_DNrTVYr73k"
   },
   "source": [
    "## 问卷调查"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bgMs1PisoSG"
   },
   "source": [
    "1. How is a grayscale image represented on a computer? How about a color image?\n",
    "1. How are the files and folders in the `MNIST_SAMPLE` dataset structured? Why?\n",
    "1. Explain how the \"pixel similarity\" approach to classifying digits works.\n",
    "1. What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n",
    "1. What is a \"rank-3 tensor\"?\n",
    "1. What is the difference between tensor rank and shape? How do you get the rank from the shape?\n",
    "1. What are RMSE and L1 norm?\n",
    "1. How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?\n",
    "1. Create a 3×3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "1. What is broadcasting?\n",
    "1. Are metrics generally calculated using the training set, or the validation set? Why?\n",
    "1. What is SGD?\n",
    "1. Why does SGD use mini-batches?\n",
    "1. What are the seven steps in SGD for machine learning?\n",
    "1. How do we initialize the weights in a model?\n",
    "1. What is \"loss\"?\n",
    "1. Why can't we always use a high learning rate?\n",
    "1. What is a \"gradient\"?\n",
    "1. Do you need to know how to calculate gradients yourself?\n",
    "1. Why can't we use accuracy as a loss function?\n",
    "1. Draw the sigmoid function. What is special about its shape?\n",
    "1. What is the difference between a loss function and a metric?\n",
    "1. What is the function to calculate new weights using a learning rate?\n",
    "1. What does the `DataLoader` class do?\n",
    "1. Write pseudocode showing the basic steps taken in each epoch for SGD.\n",
    "1. Create a function that, if passed two arguments `[1,2,3,4]` and `'abcd'`, returns `[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]`. What is special about that output data structure?\n",
    "1. What does `view` do in PyTorch?\n",
    "1. What are the \"bias\" parameters in a neural network? Why do we need them?\n",
    "1. What does the `@` operator do in Python?\n",
    "1. What does the `backward` method do?\n",
    "1. Why do we have to zero the gradients?\n",
    "1. What information do we have to pass to `Learner`?\n",
    "1. Show Python or pseudocode for the basic steps of a training loop.\n",
    "1. What is \"ReLU\"? Draw a plot of it for values from `-2` to `+2`.\n",
    "1. What is an \"activation function\"?\n",
    "1. What's the difference between `F.relu` and `nn.ReLU`?\n",
    "1. The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eecrXEaBsDr9"
   },
   "source": [
    "1. 灰度图像在计算机上是如何表示的?彩色图像怎么样?\n",
    "1. `MNIST_SAMPLE`数据集中的文件和文件夹结构如何?为什么?\n",
    "1. 解释分类数字的“像素相似性”方法是如何工作的。\n",
    "1. 什么是列表理解?现在创建一个从列表中选择奇数并将它们加倍的列表。\n",
    "1. 什么是“3阶张量”?\n",
    "1. 张量秩和形状的区别是什么?如何从形状中得到秩?\n",
    "1. 什么是RMSE和L1范数?\n",
    "1. 如何一次对数千个数字进行计算，比Python循环快数千倍?\n",
    "1. 创建一个包含从 1 到 9 的数字的 3×3 张量或数组。将其翻倍。选择右下角的四个数字。\n",
    "1. 什么是广播？\n",
    "1. 指标通常是使用训练集还是验证集来计算的?为什么?\n",
    "1. SGD是什么?\n",
    "1. 为什么SGD使用小批量?\n",
    "1. SGD中机器学习的七个步骤是什么？\n",
    "1. 如何初始化模型中的权重?\n",
    "1. 什么是“损失”?\n",
    "1. 为什么我们不能总是使用高学习率呢?\n",
    "1. 什么是“梯度”?\n",
    "1. 你需要知道如何自己计算梯度吗?\n",
    "1. 为什么我们不能用准确度作为损失函数呢?\n",
    "1. 绘制sigmoid 函数。它的形状有什么特别之处?\n",
    "1. 损失函数和指标之间的区别是什么?\n",
    "1. 使用学习率计算新权重的函数是什么?\n",
    "1. `DataLoader`类做什么?\n",
    "1. 编写伪代码，展示SGD在每个epoch中所采取的基本步骤。\n",
    "1. 创建一个函数，如果传入两个参数`[1,2,3,4]`和`'abcd'`，将返回`[(1，'a')， (2， 'b')， (3， 'c')， (4， 'd')]`。该输出数据结构有什么特别之处?\n",
    "1. `view`在PyTorch中做什么?\n",
    "1. 神经网络中的“偏差”参数是什么?我们为什么需要它们?\n",
    "1. `@`运算符在Python中做什么?\n",
    "1. `backward`方法的作用是什么?\n",
    "1. 为什么我们必须将梯度归零?\n",
    "1. 我们有什么信息要传递给`Learner`?\n",
    "1. 显示训练循环的基本步骤的 Python 或伪代码。\n",
    "1. 什么是“ReLU”?为从`-2`到`+2`的值绘制它的图。\n",
    "1. 什么是“激活函数”?\n",
    "1. `F.relu`和`nn.ReLU`有什么区别?\n",
    "1. 普遍逼近定理表明，只要使用一个非线性，任何函数都可以根据需要尽可能地逼近。那么为什么我们通常会使用更多呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFMYZXznsoSH"
   },
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap71_6fmvU94"
   },
   "source": [
    "### 进一步的研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFNhcUBLsoSH"
   },
   "source": [
    "1. Create your own implementation of `Learner` from scratch, based on the training loop shown in this chapter.\n",
    "1. Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9XCGzN9vZ3g"
   },
   "source": [
    "1. 基于本章所示的训练循环，从头开始创建你自己的`Learner`实现。\n",
    "2. 使用完整的MNIST数据集（即所有数字，而不仅仅是3和7）完成本章中的所有步骤。这是一个重要的项目，将花费你相当多的时间来完成!你需要自己做一些研究，找出如何克服途中遇到的一些障碍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtK-vjIDsoSH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SWur3woCsoQX",
    "5VPA6I1-soQf",
    "n3o3HpnJsoQs",
    "6cT7uatHsoQz"
   ],
   "name": "“04_mnist_basics.ipynb”的副本",
   "provenance": []
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
